{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from cmath import exp, sqrt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./datasets/Emails.csv\"\n",
    "headers = [\"ID of from node\",\"ID of to node\", \"weight\", \"timestamp\"]\n",
    "\n",
    "Graph = pd.read_csv(filepath, names=headers, sep=' ').drop_duplicates()\n",
    "V=np.unique((Graph['ID of from node']._append(Graph['ID of to node'])).values).astype(int)\n",
    "V_num = V.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate adjacency list for new dataset - old method\n",
    "# def getValues(i):\n",
    "#     return [ x[0] for x in Graph.loc[(Graph['ID of from node']==i), ['ID of to node']].drop_duplicates().values] + [ x[0] for x in Graph.loc[(Graph['ID of to node']==i), ['ID of from node']].drop_duplicates().values]\n",
    "\n",
    "# matrix = {i: set(getValues(i)) for i in V}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate adjacency list for new dataset - new method\n",
    "matrix = {}\n",
    "\n",
    "def add_adjacent(node, adj):\n",
    "    if node not in matrix:\n",
    "        adjacent = set()\n",
    "        adjacent.add(adj)\n",
    "        matrix[node] = adjacent\n",
    "    else:\n",
    "        matrix[node].add(adj)\n",
    "\n",
    "for index, row in Graph.iterrows():\n",
    "    u = int(row['ID of from node'])\n",
    "    v = int(row['ID of to node'])\n",
    "\n",
    "    if u == v: # to skip loops (in case they're present in dataset), because dissartotivity degree formula is 2m/n(n-1) (according to paper)\n",
    "        continue\n",
    "    \n",
    "    add_adjacent(u, v)\n",
    "    add_adjacent(v, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print adjacency list (testing purposes)\n",
    "for i in V:\n",
    "    print(matrix[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export/import generated adjacency list with whitespaces separators\n",
    "def export_adj():\n",
    "    filepath = \"./adj-lists/adjacency-list-emails.csv\"\n",
    "\n",
    "    with open(filepath, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=' ')\n",
    "\n",
    "        for node in V:\n",
    "            writer.writerow([node] + list(matrix[node]))\n",
    "\n",
    "def import_adj():\n",
    "    matrix = {}\n",
    "    filepath = \"./adj-lists/adjacency-list-emails.csv\"\n",
    "\n",
    "    with open(filepath, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=' ')\n",
    "        \n",
    "        for row in reader:\n",
    "            node = int(row[0])\n",
    "            adjacent = set(int(row[i]) for i in range(1, len(row)))\n",
    "            matrix[node] = adjacent\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call export/import functions\n",
    "# export_adj()\n",
    "matrix = import_adj()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Часть 1. \n",
    "#Задание 1\n",
    "E_num = 0\n",
    "for i in V:\n",
    "    for s in matrix[i]:\n",
    "        if s>i:\n",
    "            E_num+=1\n",
    "print(f'количество вершин: {V_num};\\nколичество ребер: {E_num};\\nплотность: {2*E_num/(V_num*(V_num-1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visited = set(V)\n",
    "Component = set()\n",
    "answer = 0\n",
    "\n",
    "while len(visited):\n",
    "    answer += 1\n",
    "    v = visited.pop()\n",
    "    comp = set([v])\n",
    "    candidates = matrix[v].copy()\n",
    "    while len(candidates):\n",
    "        newCan = set()\n",
    "        for i in candidates:\n",
    "            newCan.update(matrix[i])\n",
    "        comp.update(candidates)\n",
    "        candidates = newCan.difference(comp)\n",
    "    visited -= comp\n",
    "    if len(comp) > len(Component):\n",
    "        Component = comp.copy()\n",
    "\n",
    "\n",
    "\n",
    "print(f'Количество компонент слабой связности: {answer};\\nРазмер максимальной компоненты: {len(Component)};\\nДоля вершин в максимальной компоненте: {len(Component)/V_num}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 3\n",
    "def Cl(u):\n",
    "    if len(matrix[u])<2:\n",
    "        return 0\n",
    "    neib = matrix[u]\n",
    "    G = len(neib)\n",
    "    _2L=0\n",
    "    for our in neib:\n",
    "        _2L+=len(matrix[our].intersection(neib))\n",
    "    return _2L/(G*(G-1))\n",
    "\n",
    "CL = 0\n",
    "for node in Component:\n",
    "    CL+=Cl(node)\n",
    "print(f'средний кластерный коэффициент сети: {CL/V_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 4\n",
    "def R():\n",
    "    r1, r2, r3, re = 0, 0, 0, 0\n",
    "    for node in V:\n",
    "        u = len(matrix[node])\n",
    "        r1+=u\n",
    "        r2+=u*u\n",
    "        r3+=u*u*u\n",
    "        for to in matrix[node]:\n",
    "            re+=u*len(matrix[to])\n",
    "    return (re*r1-r2*r2)/(r3*r1-r2*r2)\n",
    "\n",
    "r = R()\n",
    "print(f'Коэффициент ассортативности: {r}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Часть 2.\n",
    "#статические характеристики\n",
    "CN_static={}\n",
    "AA_static={}\n",
    "JC_static={}\n",
    "PA_static={}\n",
    "visited=set()\n",
    "for adj in V:\n",
    "    visited.add(adj)\n",
    "    for node in matrix[adj]:\n",
    "        if node not in visited:\n",
    "            inter_adj_node = matrix[adj] & matrix[node]\n",
    "            CN_static[(adj, node)] = len(inter_adj_node)\n",
    "            AA_=0\n",
    "            for i in inter_adj_node:\n",
    "                AA_+=(1/np.log10(len(matrix[i])))\n",
    "            AA_static[(adj, node)] = AA_\n",
    "            JC_static[(adj, node)] = len(inter_adj_node)/len(matrix[adj].union(matrix[node]))\n",
    "            PA_static[(adj, node)] = len(matrix[adj])*len(matrix[node])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for weighting step\n",
    "t_min = Graph['timestamp'].min()\n",
    "t_max = Graph['timestamp'].max()\n",
    "s = (t_max-t_min) * 0.66 + t_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Timestamp_min: {t_min}')\n",
    "print(f'Timestamp_max: {t_max}')\n",
    "print(f'Separator: {s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Часть 2.\n",
    "# Построение векторов признаков для предсказания появления ребер в графе\n",
    "# create adjacency list with timestamps:\n",
    "matrix_t = dict()\n",
    "\n",
    "for u in V:\n",
    "    matrix_t[u] = dict()\n",
    "\n",
    "def add_time (parent, child, timestamp):\n",
    "    if child in matrix_t[parent]:\n",
    "        matrix_t[parent][child].add(timestamp)\n",
    "    else:\n",
    "        timeset = set()\n",
    "        timeset.add(timestamp)\n",
    "        matrix_t[parent][child] = timeset\n",
    "\n",
    "for index, _1, _2, weight, timestamp in Graph.itertuples():\n",
    "    u = _1#int(row['ID of from node'])\n",
    "    v = _2#int(row['ID of to node'])\n",
    "    #timestamp = timestamp#int(row['timestamp'])\n",
    "\n",
    "    if u == v: # skip loops\n",
    "        continue\n",
    "\n",
    "    if timestamp <= s: # work only with data from (t0, s)\n",
    "        add_time(u, v, timestamp)\n",
    "        add_time(v, u, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test purposes\n",
    "print(len(matrix_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test output for temporal adjacency matrix\n",
    "cnt = 0\n",
    "for i in matrix_t:\n",
    "    for j in matrix_t[i]:\n",
    "        cnt += len(matrix_t[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal features with past event aggreagtion (II-A)\n",
    "# Step A: temporal weighting\n",
    "l = 0.2 # same value as in paper\n",
    "\n",
    "def weight_linear(times):\n",
    "    weights = set()\n",
    "    for t in times:\n",
    "        T = (t - t_min) / (s - t_min)\n",
    "        weights.add(l + (1 - l) * T)\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def weight_exp(times):\n",
    "    weights = set()\n",
    "    for t in times:\n",
    "        T = (t - t_min) / (s - t_min)\n",
    "        weights.add(l + (1 - l) * ((exp(3 * T) - 1) / (exp(3) - 1)))\n",
    "\n",
    "    return weights\n",
    "\n",
    "def weight_square(times):\n",
    "    weights = set()\n",
    "    for t in times:\n",
    "        T = (t - t_min) / (s - t_min)\n",
    "        weights.add(l + (1 - l) * sqrt(T))\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal features with past event aggreagtion (II-A)\n",
    "# Step B: past event aggregation\n",
    "def aggregate(weights):\n",
    "    # q-quantiles are values that partition a finite set of values into q subsets of (nearly) equal sizes\n",
    "    warr = np.array(list(weights))\n",
    "\n",
    "    zeroth = warr.min() # 0th quantile = minimum\n",
    "    first = warr.max() # 1st quantile = maximum\n",
    "    second = np.median(warr) # 2nd quantile = median\n",
    "    third = np.quantile(warr, 0.3) # 3rd quantile = tertile\n",
    "    fourth = np.quantile(warr, 0.25) # 4th quantile = quartile\n",
    "\n",
    "    sum = np.sum(warr)\n",
    "    mean = np.mean(warr)\n",
    "    variance = np.var(warr)\n",
    "\n",
    "    return [zeroth, first, second, third, fourth, sum, mean, variance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal features with past event aggreagtion (II-A)\n",
    "# dict-like structure initialization (aggregated): (node1, node2): [zeroth_linear, ..., variance_linear, zeroth_exp, ..., variance_exp, zeroth_sqrt, ..., variance_sqrt]\n",
    "aggregated = dict()\n",
    "\n",
    "for node in sorted(V):\n",
    "    for adj in matrix_t[node]:\n",
    "        if adj > node:\n",
    "            # convert set of timestamps into set of weights according to formulas\n",
    "            linear = weight_linear(matrix_t[node][adj])\n",
    "            exponent = weight_exp(matrix_t[node][adj])\n",
    "            square = weight_square(matrix_t[node][adj])\n",
    "\n",
    "            res = aggregate(linear)\n",
    "            res += aggregate(exponent)\n",
    "            res += aggregate(square)\n",
    "\n",
    "            aggregated[(node, adj)] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test aggregated\n",
    "print(len(aggregated[(1, 2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal features with past event aggreagtion (II-A)\n",
    "# Step C: weighted topological features\n",
    "\n",
    "def get_aggregated(node, z, cat):\n",
    "    return aggregated[(node, z)][cat] if node < z else aggregated[(z, node)][cat]\n",
    "\n",
    "def AA_tmp(parent, child, commons, category):\n",
    "    # parent is always smaller than its child, but z - ?\n",
    "    res = 0\n",
    "\n",
    "    for z in commons:\n",
    "        num = get_aggregated(parent, z, category)\n",
    "        num += get_aggregated(child, z, category)\n",
    "\n",
    "        denum = 1\n",
    "        for x in matrix[z]:\n",
    "            denum += get_aggregated(z, x, category)\n",
    "\n",
    "        if denum == 1:\n",
    "            return 0\n",
    "\n",
    "        res += num / np.log10(denum)\n",
    "\n",
    "    return res\n",
    "\n",
    "def CN_tmp(parent, child, commons, category):\n",
    "    res = 0\n",
    "\n",
    "    for z in commons:\n",
    "        res += get_aggregated(parent, z, category)\n",
    "        res += get_aggregated(child, z, category)\n",
    "\n",
    "    return res\n",
    "\n",
    "def JC_tmp(parent, child, commons, category):\n",
    "    res = 0\n",
    "\n",
    "    for z in commons:\n",
    "        num = get_aggregated(parent, z, category)\n",
    "        num += get_aggregated(child, z, category)\n",
    "\n",
    "        denum = 0\n",
    "        for x in matrix[parent]:\n",
    "            denum += get_aggregated(parent, x, category)\n",
    "        for x in matrix[child]:\n",
    "            denum += get_aggregated(child, x, category)\n",
    "        \n",
    "        if denum == 0:\n",
    "            return 0\n",
    "        \n",
    "        res += num / denum\n",
    "    \n",
    "    return res\n",
    "\n",
    "def PA_tmp(parent, child, commons, category):\n",
    "    ares = 0\n",
    "    bres = 0\n",
    "\n",
    "    for a in matrix[parent]:\n",
    "        ares += get_aggregated(parent, a, category)\n",
    "    for b in matrix[child]:\n",
    "        bres += get_aggregated(child, b, category)\n",
    "    \n",
    "    return ares * bres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(matrix_t.keys()))\n",
    "# print(list(matrix_t[1].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose potential pairs\n",
    "# (u, v) with distance 2 (so they're not connected in [t0, s])\n",
    "potential_pairs = dict()\n",
    "\n",
    "for u in V:\n",
    "    u_adj = set(matrix_t[u].keys())\n",
    "    for v in V:\n",
    "        v_adj = set(matrix_t[v].keys())\n",
    "        if u not in matrix_t[v].keys() and u_adj.intersection(v_adj):\n",
    "            if u < v:\n",
    "                potential_pairs[(u, v)] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "for u, v in potential_pairs.keys():\n",
    "    print(u, v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all yes/no pairs from potential pairs\n",
    "# y_sample: will connect in (s, t1]\n",
    "# n_sample: won't connect in (s, t1]\n",
    "y_sample = dict()\n",
    "n_sample = dict()\n",
    "\n",
    "for u, v in potential_pairs.keys():\n",
    "    if v in matrix[u]:\n",
    "        y_sample[(u, v)] = []\n",
    "\n",
    "leftovers = set(potential_pairs.keys()).difference(set(y_sample.keys()))\n",
    "\n",
    "for u, v in leftovers:\n",
    "    n_sample[(u, v)] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(potential_pairs.keys()))\n",
    "print(len(y_sample.keys()))\n",
    "print(len(n_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u, v in y_sample:\n",
    "    print(\"Will connect:\", u, v)\n",
    "    print(len(y_sample))\n",
    "    break\n",
    "\n",
    "for u, v in n_sample:\n",
    "    print(\"Will not connect:\", u, v)\n",
    "    print(len(n_sample))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad way of initializing sampling of yes\\no\n",
    "stop = 500\n",
    "y_sample = dict()\n",
    "n_sample = dict()\n",
    "\n",
    "for index, _1, _2, weight, timestamp in Graph.itertuples():\n",
    "    u = _1#int(row['ID of from node'])\n",
    "    v = _2#int(row['ID of to node'])\n",
    "    #timestamp = timestamp#int(row['timestamp'])\n",
    "\n",
    "    if u == v: # skip loops\n",
    "        continue\n",
    "\n",
    "    if (u, v) in potential_pairs.keys() and timestamp > s:\n",
    "        if len(y_sample) >= stop:\n",
    "            break\n",
    "\n",
    "        y_sample[(u, v)] = []\n",
    "\n",
    "    if (v, u) in potential_pairs.keys():\n",
    "        if len(y_sample) >= stop:\n",
    "            break\n",
    "\n",
    "        y_sample[(v, u)] = []\n",
    "\n",
    "leftovers = set(potential_pairs.keys()).difference(set(y_sample.keys()))\n",
    "\n",
    "for u, v in leftovers:\n",
    "    if len(n_sample) >= stop:\n",
    "        break\n",
    "\n",
    "    n_sample[(u, v)] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal features with past event aggreagtion (II-A)\n",
    "# Step C: weighted topological features;\n",
    "for parent, child in range(10000):\n",
    "    for i in range(24):\n",
    "        commons = matrix[parent].intersection(matrix[child])\n",
    "        feature_vect[(parent, child)].append(AA_tmp(parent, child, commons, i))\n",
    "        feature_vect[(parent, child)].append(CN_tmp(parent, child, commons, i))\n",
    "        feature_vect[(parent, child)].append(JC_tmp(parent, child, commons, i))\n",
    "        feature_vect[(parent, child)].append(PA_tmp(parent, child, commons, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test output for feature vector\n",
    "print(feature_vect[(1,2)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
