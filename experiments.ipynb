{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    \"data/opsahl-ucsocial/out.opsahl-ucsocial\",\n",
    "    \"data/soc-sign-bitcoinalpha/out.soc-sign-bitcoinalpha\",\n",
    "    \"data/soc-sign-bitcoinotc/out.soc-sign-bitcoinotc\",\n",
    "    \"data/digg-friends/out.digg-friends\",\n",
    "    \"data/prosper-loans/out.prosper-loans\"]\n",
    "skiprows = [[0, 1], [0], [0], [0], [0]]\n",
    "current = 0 # 3 is big n (n = 270000), 4 is big volume (n = 90000)\n",
    "graph = pd.read_csv(\n",
    "    datasets[current],\n",
    "    names=[\"_from\", \"_to\", \"_weight\", \"_timestamp\"],\n",
    "    sep=\" |\\t\",\n",
    "    engine ='python',\n",
    "    skiprows=skiprows[current]\n",
    ")\n",
    "# print(graph.dtypes)\n",
    "# print(graph.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "V = np.unique(graph[\"_from\"]._append(graph[\"_to\"]))\n",
    "n = V.size\n",
    "volume = graph[\"_timestamp\"].size\n",
    "print(f\"{n = }, {volume = }\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparing static graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "graph_static = [set() for _ in range(n + 1)]\n",
    "for _index, _from, _to, _weight, _timestamp in graph.itertuples():\n",
    "    if _from == _to:\n",
    "        continue\n",
    "    graph_static[_from].add(_to)\n",
    "    graph_static[_to].add(_from)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "E_count = 0\n",
    "for i in range(len(graph_static)):\n",
    "    E_count += len(graph_static[i])\n",
    "E_count //= 2\n",
    "#print(E_count)\n",
    "\n",
    "density = E_count * 2 / (n * (n - 1))\n",
    "#print(density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "V_to_visit = set(V)\n",
    "connectivity_components = []\n",
    "while(V_to_visit):\n",
    "    V_seen = set()\n",
    "    queue = []\n",
    "    for u in V_to_visit:\n",
    "        queue.append(u)\n",
    "        V_seen.add(u)\n",
    "        break\n",
    "    while queue:\n",
    "        u = queue.pop()\n",
    "        u_adjacent_to_visit = graph_static[u].difference(V_seen)\n",
    "        for v in u_adjacent_to_visit:\n",
    "            V_seen.add(v)\n",
    "            queue.append(v)\n",
    "    V_to_visit = V_to_visit.difference(V_seen)\n",
    "    connectivity_components.append(V_seen)\n",
    "\n",
    "sizes = list(map(lambda x: len(x), connectivity_components))\n",
    "max_component_size = max(sizes)\n",
    "max_connectivity_component_index = sizes.index(max_component_size)\n",
    "proportion = max_component_size / len(V)\n",
    "#print(f\"{max_val = }, {max_connectivity_component_index = }, {proportion = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1.1\n",
    "print(\"|V| = %i, |E| = %i, p = %f, number of components = %i, max component size = %i, max component proportion= % f\"\n",
    "      % (n, E_count, density, len(connectivity_components), max_component_size, proportion))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "component = list(connectivity_components[max_connectivity_component_index])\n",
    "distances = [0] * (n + 2)\n",
    "diameter = 0\n",
    "radius = n + 1\n",
    "distances_tmp = np.empty(n + 1, dtype=int)\n",
    "if(n < 10000):\n",
    "    for start in component:\n",
    "        distances_tmp.fill(n + 1)\n",
    "        V_visited = set()\n",
    "        queue = [(start, 0)]\n",
    "        queued = set([start])\n",
    "        depth = 0\n",
    "        u = start\n",
    "        while queued:\n",
    "            (u, depth) = queue.pop(0)\n",
    "            queued.remove(u)\n",
    "            V_visited.add(u)\n",
    "            u_adjacent_to_visit = graph_static[u].difference(V_visited)\n",
    "            for v in u_adjacent_to_visit:\n",
    "                distances_tmp[v] = min(distances_tmp[v], depth + 1)\n",
    "                if v not in queued:\n",
    "                    queue.append((v, depth + 1))\n",
    "                    queued.add(v)\n",
    "        for d in range(start, n + 1):\n",
    "            distances[distances_tmp[d]] += 1\n",
    "        diameter = max(diameter, depth)\n",
    "        radius = min(radius, depth)\n",
    "        if not start % 10:\n",
    "            # print(start, \"/\", n)\n",
    "            pass\n",
    "#print(distances)\n",
    "all_dist = 0\n",
    "for i in range(diameter + 1):\n",
    "    all_dist += distances[i]\n",
    "print(all_dist, \"=\", max_component_size * (max_component_size - 1) // 2,\n",
    "      all_dist == max_component_size * (max_component_size - 1) // 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#percentile_90 = np.percentile(all_distances, 90)\n",
    "percentile_90_ind = int(0.9 * all_dist)\n",
    "percentile_90 = 0\n",
    "ind_tmp = 0\n",
    "for i in range(diameter + 1):\n",
    "    ind_tmp += distances[i]\n",
    "    if ind_tmp >= percentile_90_ind:\n",
    "        percentile_90 = i\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_matrix(vertices):\n",
    "\n",
    "    vertices_list = list(vertices)\n",
    "    vertices_set = set(vertices)\n",
    "\n",
    "    distances = []\n",
    "    distance_matrix = dict()\n",
    "    for u in vertices_list:\n",
    "        distance_matrix[u] = dict()\n",
    "        for v in vertices_list:\n",
    "            if u != v:\n",
    "                distance_matrix[u][v] = n + 1\n",
    "\n",
    "    for start in vertices_list:\n",
    "        V_to_calculate = set(vertices)\n",
    "        V_to_calculate.discard(start)\n",
    "        V_visited = set()\n",
    "        queue = [(start, 0)]\n",
    "        queued = set([start])\n",
    "        max_depth = 0\n",
    "        while queued and V_to_calculate:\n",
    "            u, depth = queue.pop(0)\n",
    "            max_depth = max(max_depth, depth)\n",
    "            queued.discard(u)\n",
    "            V_visited.add(u)\n",
    "            u_adjacent_to_visit = graph_static[u].difference(V_visited)\n",
    "            for v in u_adjacent_to_visit:\n",
    "                if v in V_to_calculate:\n",
    "                    distance = distance_matrix[start][v]\n",
    "                    if depth + 1 < distance:\n",
    "                        distance_matrix[start][v] = depth + 1\n",
    "                        distance_matrix[v][start] = depth + 1\n",
    "                        V_to_calculate.discard(v)\n",
    "                if v not in queued:\n",
    "                    queue.append((v, depth + 1))\n",
    "                    queued.add(v)\n",
    "    \n",
    "    for u in vertices_list:\n",
    "        for v in vertices_list:\n",
    "            if u > v:\n",
    "                distances.append(distance_matrix[u][v])\n",
    "    eccentricities = dict()\n",
    "    for u in distance_matrix:\n",
    "        eccentricities[u] = max(distance_matrix[u].values())\n",
    "\n",
    "    return (distance_matrix, eccentricities, distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "component = list(connectivity_components[max_connectivity_component_index])\n",
    "\n",
    "random_500_vertices = sorted(random.sample(component, 500))\n",
    "random_1000_vertices = sorted(random.sample(component, 1000))\n",
    "\n",
    "random_500_matrix, random_500_eccentricities, random_500_distances = calculate_matrix(\n",
    "    random_500_vertices)\n",
    "random_1000_matrix, random_1000_eccentricities, random_1000_distances = calculate_matrix(\n",
    "    random_1000_vertices)\n",
    "\n",
    "diameter_from_random_500 = max(random_500_eccentricities.values())\n",
    "radius_from_random_500 = min(random_500_eccentricities.values())\n",
    "percentile_90_from_random_500 = np.percentile(random_500_distances, 90)\n",
    "\n",
    "print(f\"{diameter_from_random_500 = }, {radius_from_random_500 = }, {percentile_90_from_random_500 = }\")\n",
    "\n",
    "diameter_from_random_1000 = max(random_1000_eccentricities.values())\n",
    "radius_from_random_1000 = min(random_1000_eccentricities.values())\n",
    "percentile_90_from_random_1000 = np.percentile(random_1000_distances, 90)\n",
    "\n",
    "print(f\"{diameter_from_random_1000 = }, {radius_from_random_1000 = }, {percentile_90_from_random_1000 = }\")\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def snowball(limit):\n",
    "    vertices = {component[0], component[1]}\n",
    "    while len(vertices) < limit:\n",
    "        for v in vertices:\n",
    "            if len(vertices) < limit:\n",
    "                vertices = vertices.union(graph_static[v])\n",
    "    return sorted(list(vertices))\n",
    "\n",
    "snowball_500_vertices = snowball(500)\n",
    "snowball_1000_vertices = snowball(1000)\n",
    "\n",
    "snowball_500_matrix, snowball_500_eccentricities, snowball_500_distances = calculate_matrix(\n",
    "    snowball_500_vertices)\n",
    "snowball_1000_matrix, snowball_1000_eccentricities, snowball_1000_distances = calculate_matrix(\n",
    "    snowball_1000_vertices)\n",
    "\n",
    "diameter_from_snowball_500 = max(snowball_500_eccentricities.values())\n",
    "radius_from_snowball_500 = min(snowball_500_eccentricities.values())\n",
    "percentile_90_from_snowball_500 = np.percentile(snowball_500_distances, 90)\n",
    "\n",
    "print(f\"{diameter_from_snowball_500 = }, {radius_from_snowball_500 = }, {percentile_90_from_snowball_500 = }\")\n",
    "\n",
    "diameter_from_snowball_1000 = max(snowball_1000_eccentricities.values())\n",
    "radius_from_snowball_1000 = min(snowball_1000_eccentricities.values())\n",
    "percentile_90_from_snowball_1000 = np.percentile(snowball_1000_distances, 90)\n",
    "\n",
    "print(f\"{diameter_from_snowball_1000 = }, {radius_from_snowball_1000 = }, {percentile_90_from_snowball_1000 = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1.2\n",
    "print(\"diameter = %i, raduis = %i, percentile_90 = %i\" \n",
    "      % (diameter, radius, percentile_90))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "component = list(connectivity_components[max_connectivity_component_index])\n",
    "\n",
    "Cl = dict()\n",
    "for u in component:\n",
    "    u_neighbors = graph_static[u]\n",
    "\n",
    "    if len(u_neighbors) < 2:\n",
    "        Cl[u] = 0\n",
    "        continue\n",
    "\n",
    "    Lu_doubled = 0\n",
    "    for neighbor in u_neighbors:\n",
    "        Lu_doubled += len(graph_static[neighbor].intersection(u_neighbors))\n",
    "    Cl[u] = Lu_doubled / (len(u_neighbors) * (len(u_neighbors) - 1))\n",
    "\n",
    "Cl_average = sum(Cl.values()) / len(Cl.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#1.3\n",
    "print(\"Cl_average = %f\" % (Cl_average))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "R1 = 0\n",
    "R2 = 0\n",
    "R3 = 0\n",
    "Re = 0\n",
    "for i in range(1, n + 1):\n",
    "    ki = len(graph_static[i])\n",
    "    R1 += ki\n",
    "    R2 += ki**2\n",
    "    R3 += ki**3\n",
    "    for j in graph_static[i]:\n",
    "        kj = len(graph_static[j])\n",
    "        Re += ki * kj\n",
    "degree_associativity = (Re * R1 - R2**2) / (R3 * R1 - R2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Degree associativity = %f\" % (degree_associativity))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Static topological features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_static_topological_features():\n",
    "    CN_static = {}\n",
    "    AA_static = {}\n",
    "    JC_static = {}\n",
    "    PA_static = {}\n",
    "    \n",
    "    visited = set()\n",
    "    for u in V:\n",
    "        visited.add(u)\n",
    "        for v in graph_static[u]:\n",
    "            if v in visited:\n",
    "                continue\n",
    "            gamma_u = graph_static[u]\n",
    "            gamma_v = graph_static[v]\n",
    "            \n",
    "            intersection_u_v = gamma_u.intersection(gamma_v)\n",
    "            CN_static[(u, v)] = len(intersection_u_v)\n",
    "            JC_static[(u, v)] = CN_static[(u, v)] / len(gamma_u.union(gamma_v))\n",
    "            PA_static[(u, v)] = len(gamma_u) * len(gamma_v)\n",
    "            AA_static[(u, v)] = sum([1.0 / np.log(len(graph_static[z])) for z in intersection_u_v])\n",
    "    return CN_static, AA_static, JC_static, PA_static\n",
    "\n",
    "CN_static, AA_static, JC_static, PA_static = get_static_topological_features()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Node activity features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t_min = graph[\"_timestamp\"].min()\n",
    "t_max = graph[\"_timestamp\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_temporal_weighting(l, t):\n",
    "    \"\"\"\n",
    "    Node acticvity features: STEP 1\n",
    "    \"\"\"\n",
    "    time_var = (t - t_min) / (t_max - t_min)\n",
    "    w_linear = l + (1 - l) * time_var\n",
    "    w_exponential = l + (1 - l) * (np.exp(3 * time_var) - 1) / (np.exp(3) - 1)\n",
    "    w_square_root = l + (1 - l) * np.sqrt(time_var)\n",
    "    return w_linear, w_exponential, w_square_root\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AggregationOfNodeActivity:\n",
    "    \"\"\"\n",
    "    Node acticvity features: STEP 2\n",
    "    \"\"\" \n",
    "    @staticmethod\n",
    "    def get_weights() -> list[set]:\n",
    "        \"\"\"\n",
    "        List with the sets of weights from all edges adjacent to the node.\n",
    "        \"\"\"\n",
    "        weights = [set() for _ in range(n + 1)]\n",
    "        for _index, _from, _to, _weight, _timestamp in graph.itertuples():\n",
    "            if _from == _to:\n",
    "                continue\n",
    "            weights[_from].add(_weight)\n",
    "            weights[_to].add(_weight)\n",
    "        return weights\n",
    "    \n",
    "    @staticmethod\n",
    "    def zeroth_quantile(weights):\n",
    "        return np.quantile(weights, 0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def first_quantile(weights):\n",
    "        return np.quantile(weights, 0.25)\n",
    "    \n",
    "    @staticmethod\n",
    "    def second_quantile(weights):\n",
    "        return np.quantile(weights, 0.50)\n",
    "    \n",
    "    @staticmethod\n",
    "    def third_quantile(weights):\n",
    "        return np.quantile(weights, 0.75)\n",
    "    \n",
    "    @staticmethod\n",
    "    def fourth_quantile(weights):\n",
    "        return np.quantile(weights, 1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_sum(weights):\n",
    "        return sum(weights)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_mean(weights):\n",
    "        return np.mean(weights)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CombiningNodeActivity:\n",
    "    \"\"\"\n",
    "    Node acticvity features: STEP 3\n",
    "    \"\"\" \n",
    "    @staticmethod\n",
    "    def get_sum(a, b):\n",
    "        return a + b\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_absolute_differrence(a, b):\n",
    "        return math.abs(a - b)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_minimum(a, b):\n",
    "        return min(a, b)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_maximum(a, b):\n",
    "        return max(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class AggregationOfNodeActivity:\n",
    "    \"\"\"\n",
    "    Node acticvity features: STEP 2\n",
    "    \"\"\" \n",
    "    @staticmethod\n",
    "    def get_weights() -> list[set]:\n",
    "        \"\"\"\n",
    "        List with the sets of weights from all edges adjacent to the node.\n",
    "        \"\"\"\n",
    "        weights = [set() for _ in range(n + 1)]\n",
    "        for _index, _from, _to, _weight, _timestamp in graph.itertuples():\n",
    "            if _from == _to:\n",
    "                continue\n",
    "            weights[_from].add(_weight)\n",
    "            weights[_to].add(_weight)\n",
    "        return weights\n",
    "    \n",
    "    @staticmethod\n",
    "    def zeroth_quantile(weights):\n",
    "        return np.quantile(weights, 0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def first_quantile(weights):\n",
    "        return np.quantile(weights, 0.25)\n",
    "    \n",
    "    @staticmethod\n",
    "    def second_quantile(weights):\n",
    "        return np.quantile(weights, 0.50)\n",
    "    \n",
    "    @staticmethod\n",
    "    def third_quantile(weights):\n",
    "        return np.quantile(weights, 0.75)\n",
    "    \n",
    "    @staticmethod\n",
    "    def fourth_quantile(weights):\n",
    "        return np.quantile(weights, 1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_sum(weights):\n",
    "        return sum(weights)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_mean(weights):\n",
    "        return np.mean(weights)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CombiningNodeActivity:\n",
    "    \"\"\"\n",
    "    Node acticvity features: STEP 3\n",
    "    \"\"\" \n",
    "    @staticmethod\n",
    "    def get_sum(a, b):\n",
    "        return a + b\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_absolute_differrence(a, b):\n",
    "        return abs(a - b)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_minimum(a, b):\n",
    "        return min(a, b)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_maximum(a, b):\n",
    "        return max(a, b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombiningNodeActivity:\n",
    "    \"\"\"\n",
    "    Node acticvity features: STEP 3\n",
    "    \"\"\" \n",
    "    @staticmethod\n",
    "    def get_sum(a, b):\n",
    "        return a + b\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_absolute_differrence(a, b):\n",
    "        return abs(a - b)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_minimum(a, b):\n",
    "        return min(a, b)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_maximum(a, b):\n",
    "        return max(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}