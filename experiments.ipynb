{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "graph = pd.read_csv(\n",
    "    \"data/opsahl-ucsocial/out.opsahl-ucsocial\", \n",
    "    names=[\"from\", \"to\", \"weight\", \"timestamp\"],\n",
    "    sep=\" |\\t\",\n",
    "    engine ='python',\n",
    "    skiprows=[0, 1]\n",
    ")\n",
    "#print(graph.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 1899, volume = 59835\n"
     ]
    }
   ],
   "source": [
    "V = np.unique(graph[\"from\"]._append(graph[\"to\"]))\n",
    "n = V.size\n",
    "volume = graph[\"timestamp\"].size\n",
    "print(f\"{n = }, {volume = }\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparing static graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "graph_static = [set() for _ in range(n +1)]\n",
    "for row_number, row in graph.iterrows():\n",
    "    graph_static[row[\"from\"]].add(row[\"to\"])\n",
    "    graph_static[row[\"to\"]].add(row[\"from\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "E_count = 0\n",
    "for i in range(len(graph_static)):\n",
    "    E_count += len(graph_static[i])\n",
    "E_count //= 2\n",
    "#print(E_count)\n",
    "\n",
    "density = E_count * 2 / (n * (n - 1))\n",
    "#print(density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "V_to_visit = set(V)\n",
    "connectivity_components = []\n",
    "while(V_to_visit):\n",
    "    V_visited = set()\n",
    "    queue = []\n",
    "    for u in V_to_visit:\n",
    "        queue.append(u)\n",
    "        break\n",
    "    while queue:\n",
    "        u = queue.pop()\n",
    "        V_to_visit.discard(u)\n",
    "        V_visited.add(u)\n",
    "        u_adjacent_to_visit = graph_static[u].difference(V_visited)\n",
    "        for v in u_adjacent_to_visit:\n",
    "            if v not in queue:\n",
    "                queue.append(v)\n",
    "    connectivity_components.append(V_visited)\n",
    "\n",
    "sizes = list(map(lambda x: len(x), connectivity_components))\n",
    "max_val = max(sizes)\n",
    "max_connectivity_component_index = sizes.index(max_val)\n",
    "proportion = max_val / len(V)\n",
    "#print(f\"{max_val = }, {max_connectivity_component_index = }, {proportion = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|V| = 1899, |E| = 13838, p = 0.007679, number of components = 4, max component proportion = 0.996840\n"
     ]
    }
   ],
   "source": [
    "# 1.1\n",
    "print(\"|V| = %i, |E| = %i, p = %f, number of components = %i, max component proportion = %f\" \n",
    "      % (n, E_count, density, len(connectivity_components), proportion))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "component = list(connectivity_components[max_connectivity_component_index])\n",
    "# infinite distance = n + 1\n",
    "distance_matrix = [[n + 1 for j in range(n + 1)] for i in range(n + 1)]\n",
    "eccentricities = dict()\n",
    "for start in component:\n",
    "    V_visited = set()\n",
    "    queue = [(start, 0)]\n",
    "    queued = set([start])\n",
    "    max_depth = 0\n",
    "    while queue:\n",
    "        u, depth = queue.pop(0)\n",
    "        max_depth = max(max_depth, depth)\n",
    "        queued.discard(u)\n",
    "        V_visited.add(u)\n",
    "        u_adjacent_to_visit = graph_static[u].difference(V_visited)\n",
    "        for v in u_adjacent_to_visit:\n",
    "            if v not in queued:\n",
    "                distance = distance_matrix[start][v]\n",
    "                if depth + 1 < distance:\n",
    "                    distance_matrix[start][v] = depth + 1\n",
    "                    distance_matrix[v][start] = depth + 1\n",
    "                queue.append((v, depth + 1))\n",
    "                queued.add(v)\n",
    "    eccentricities[start] = max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "component = set(connectivity_components[max_connectivity_component_index])\n",
    "\n",
    "diameter = max(eccentricities.values())\n",
    "radius = min(eccentricities.values())\n",
    "\n",
    "all_distances = []\n",
    "for i in range(1, n + 1):\n",
    "    for j in range(i + 1, n + 1):\n",
    "        if i in component and j in component:\n",
    "            all_distances.append(distance_matrix[i][j])\n",
    "all_distances.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "percentile_90 = np.percentile(all_distances, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diameter_from_random_500 = 8, radius_from_random_500 = 4, percentile_90_from_random_500 = 4.0\n",
      "diameter_from_random_1000 = 8, radius_from_random_1000 = 4, percentile_90_from_random_1000 = 4.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "component = list(connectivity_components[max_connectivity_component_index])\n",
    "\n",
    "random_500_vertices = sorted(random.sample(component, 500))\n",
    "random_1000_vertices = sorted(random.sample(component, 1000))\n",
    "\n",
    "\n",
    "def get_random_distances(vertices):\n",
    "    distances = []\n",
    "    for i in range(len(vertices) - 1):\n",
    "        for j in range(i + 1, len(vertices)):\n",
    "            u = vertices[i]\n",
    "            v = vertices[j]\n",
    "            distances.append(distance_matrix[u][v])\n",
    "    return distances\n",
    "\n",
    "random_500_eccentricities = [eccentricities[v] for v in random_500_vertices]\n",
    "random_1000_eccentricities = [eccentricities[v] for v in random_1000_vertices]\n",
    "\n",
    "random_500_distances = get_random_distances(random_500_vertices)    \n",
    "random_1000_distances = get_random_distances(random_1000_vertices)  \n",
    "\n",
    "diameter_from_random_500 = max(random_500_eccentricities)\n",
    "radius_from_random_500 = min(random_500_eccentricities)\n",
    "percentile_90_from_random_500 = np.percentile(random_500_distances, 90)\n",
    "\n",
    "print(f\"{diameter_from_random_500 = }, {radius_from_random_500 = }, {percentile_90_from_random_500 = }\")\n",
    "\n",
    "diameter_from_random_1000 = max(random_1000_eccentricities)\n",
    "radius_from_random_1000 = min(random_1000_eccentricities)\n",
    "percentile_90_from_random_1000 = np.percentile(random_1000_distances, 90)\n",
    "\n",
    "print(f\"{diameter_from_random_1000 = }, {radius_from_random_1000 = }, {percentile_90_from_random_1000 = }\")\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diameter_from_snowball_500 = 6, radius_from_snowball_500 = 4, percentile_90_from_snowball_500 = 3.0\n",
      "diameter_from_snowball_1000 = 6, radius_from_snowball_1000 = 4, percentile_90_from_snowball_1000 = 3.0\n"
     ]
    }
   ],
   "source": [
    "def snowball(limit):\n",
    "    vertices = {1, 2}\n",
    "    while len(vertices) < limit:\n",
    "        for v in vertices:\n",
    "            if len(vertices) < limit:\n",
    "                vertices = vertices.union(graph_static[v])\n",
    "    return sorted(list(vertices))\n",
    "\n",
    "\n",
    "snowball_vertices_500 = snowball(500)\n",
    "snowball_vertices_1000 = snowball(1000)\n",
    "\n",
    "\n",
    "snowball_500_eccentricities = [eccentricities[v] for v in snowball_vertices_500]\n",
    "snowball_1000_eccentricities = [eccentricities[v] for v in snowball_vertices_1000]\n",
    "\n",
    "snowball_500_distances = get_random_distances(snowball_vertices_500)    \n",
    "snowball_1000_distances = get_random_distances(snowball_vertices_1000)  \n",
    "\n",
    "diameter_from_snowball_500 = max(snowball_500_eccentricities)\n",
    "radius_from_snowball_500 = min(snowball_500_eccentricities)\n",
    "percentile_90_from_snowball_500 = np.percentile(snowball_500_distances, 90)\n",
    "\n",
    "print(f\"{diameter_from_snowball_500 = }, {radius_from_snowball_500 = }, {percentile_90_from_snowball_500 = }\")\n",
    "\n",
    "diameter_from_snowball_1000 = max(snowball_1000_eccentricities)\n",
    "radius_from_snowball_1000 = min(snowball_1000_eccentricities)\n",
    "percentile_90_from_snowball_1000 = np.percentile(snowball_1000_distances, 90)\n",
    "\n",
    "print(f\"{diameter_from_snowball_1000 = }, {radius_from_snowball_1000 = }, {percentile_90_from_snowball_1000 = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diameter = 8, raduis = 4, percentile_90 = 4\n"
     ]
    }
   ],
   "source": [
    "# 1.2\n",
    "print(\"diameter = %i, raduis = %i, percentile_90 = %i\" \n",
    "      % (diameter, radius, percentile_90))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "component = list(connectivity_components[max_connectivity_component_index])\n",
    "\n",
    "Cl = dict()\n",
    "for u in component:\n",
    "    u_neighbors = graph_static[u]\n",
    "\n",
    "    if len(u_neighbors) < 2:\n",
    "        Cl[u] = 0\n",
    "        continue\n",
    "\n",
    "    Lu_doubled = 0\n",
    "    for neighbor in u_neighbors:\n",
    "        Lu_doubled += len(graph_static[neighbor].intersection(u_neighbors))\n",
    "    Cl[u] = Lu_doubled / (len(u_neighbors) * (len(u_neighbors) - 1))\n",
    "\n",
    "Cl_average = sum(Cl.values()) / len(Cl.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cl_average = 0.109746\n"
     ]
    }
   ],
   "source": [
    "#1.3\n",
    "print(\"Cl_average = %f\" % (Cl_average))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "R1 = 0\n",
    "R2 = 0\n",
    "R3 = 0\n",
    "Re = 0\n",
    "for i in range(1, n + 1):\n",
    "    ki = len(graph_static[i])\n",
    "    R1 += ki\n",
    "    R2 += ki**2\n",
    "    R3 += ki**3\n",
    "    for j in range(1, n + 1):\n",
    "        if j in graph_static[i]:\n",
    "            kj = len(graph_static[j])\n",
    "            Re += ki * kj\n",
    "degree_associativity = (Re * R1 - R2**2) / (R3 * R1 - R2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree associativity = 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Degree associativity = %i\" % (degree_associativity))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
