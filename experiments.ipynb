{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    \"data/opsahl-ucsocial/out.opsahl-ucsocial\",\n",
    "    \"data/soc-sign-bitcoinalpha/out.soc-sign-bitcoinalpha\",\n",
    "    \"data/soc-sign-bitcoinotc/out.soc-sign-bitcoinotc\"\n",
    "]\n",
    "skiprows = [[0, 1], [0], [0]]\n",
    "current = 1\n",
    "graph = pd.read_csv(\n",
    "    datasets[current],\n",
    "    names=[\"_from\", \"_to\", \"_weight\", \"_timestamp\"],\n",
    "    sep=\" |\\t\",\n",
    "    engine ='python',\n",
    "    skiprows=skiprows[current]\n",
    ")\n",
    "# print(graph.dtypes)\n",
    "# print(graph.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 3783, volume = 24186\n"
     ]
    }
   ],
   "source": [
    "V = np.unique(graph[\"_from\"]._append(graph[\"_to\"]))\n",
    "n = V.size\n",
    "volume = graph[\"_timestamp\"].size\n",
    "print(f\"{n = }, {volume = }\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparing static graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "graph_static = [set() for _ in range(n + 1)]\n",
    "for _index, _from, _to, _weight, _timestamp in graph.itertuples():\n",
    "    if _from == _to:\n",
    "        continue\n",
    "    graph_static[_from].add(_to)\n",
    "    graph_static[_to].add(_from)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "E_count = 0\n",
    "for i in range(len(graph_static)):\n",
    "    E_count += len(graph_static[i])\n",
    "E_count //= 2\n",
    "#print(E_count)\n",
    "\n",
    "density = E_count * 2 / (n * (n - 1))\n",
    "#print(density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "V_to_visit = set(V)\n",
    "connectivity_components = []\n",
    "while(V_to_visit):\n",
    "    V_seen = set()\n",
    "    queue = []\n",
    "    for u in V_to_visit:\n",
    "        queue.append(u)\n",
    "        V_seen.add(u)\n",
    "        break\n",
    "    while queue:\n",
    "        u = queue.pop()\n",
    "        u_adjacent_to_visit = graph_static[u].difference(V_seen)\n",
    "        for v in u_adjacent_to_visit:\n",
    "            V_seen.add(v)\n",
    "            queue.append(v)\n",
    "    V_to_visit = V_to_visit.difference(V_seen)\n",
    "    connectivity_components.append(V_seen)\n",
    "\n",
    "sizes = list(map(lambda x: len(x), connectivity_components))\n",
    "max_component_size = max(sizes)\n",
    "max_connectivity_component_index = sizes.index(max_component_size)\n",
    "proportion = max_component_size / len(V)\n",
    "#print(f\"{max_val = }, {max_connectivity_component_index = }, {proportion = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|V| = 3783, |E| = 14124, p = 0.001974, number of components = 5, max component size = 3775, max component proportion=  0.997885\n"
     ]
    }
   ],
   "source": [
    "# 1.1\n",
    "print(\"|V| = %i, |E| = %i, p = %f, number of components = %i, max component size = %i, max component proportion= % f\"\n",
    "      % (n, E_count, density, len(connectivity_components), max_component_size, proportion))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7123425 = 7123425 True\n"
     ]
    }
   ],
   "source": [
    "component = list(connectivity_components[max_connectivity_component_index])\n",
    "distances = [0] * (n + 2)\n",
    "diameter = 0\n",
    "radius = n + 1\n",
    "distances_tmp = np.empty(n + 1, dtype=int)\n",
    "if(n < 10000):\n",
    "    for start in component:\n",
    "        distances_tmp.fill(n + 1)\n",
    "        V_visited = set()\n",
    "        queue = [(start, 0)]\n",
    "        queued = set([start])\n",
    "        depth = 0\n",
    "        u = start\n",
    "        while queued:\n",
    "            (u, depth) = queue.pop(0)\n",
    "            queued.remove(u)\n",
    "            V_visited.add(u)\n",
    "            u_adjacent_to_visit = graph_static[u].difference(V_visited)\n",
    "            for v in u_adjacent_to_visit:\n",
    "                distances_tmp[v] = min(distances_tmp[v], depth + 1)\n",
    "                if v not in queued:\n",
    "                    queue.append((v, depth + 1))\n",
    "                    queued.add(v)\n",
    "        for d in range(start, n + 1):\n",
    "            distances[distances_tmp[d]] += 1\n",
    "        diameter = max(diameter, depth)\n",
    "        radius = min(radius, depth)\n",
    "        if not start % 10:\n",
    "            # print(start, \"/\", n)\n",
    "            pass\n",
    "#print(distances)\n",
    "all_dist = 0\n",
    "for i in range(diameter + 1):\n",
    "    all_dist += distances[i]\n",
    "print(all_dist, \"=\", max_component_size * (max_component_size - 1) // 2,\n",
    "      all_dist == max_component_size * (max_component_size - 1) // 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#percentile_90 = np.percentile(all_distances, 90)\n",
    "percentile_90_ind = int(0.9 * all_dist)\n",
    "percentile_90 = 0\n",
    "ind_tmp = 0\n",
    "for i in range(diameter + 1):\n",
    "    ind_tmp += distances[i]\n",
    "    if ind_tmp >= percentile_90_ind:\n",
    "        percentile_90 = i\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_matrix(vertices):\n",
    "\n",
    "    vertices_list = list(vertices)\n",
    "    vertices_set = set(vertices)\n",
    "\n",
    "    distances = []\n",
    "    distance_matrix = dict()\n",
    "    for u in vertices_list:\n",
    "        distance_matrix[u] = dict()\n",
    "        for v in vertices_list:\n",
    "            if u != v:\n",
    "                distance_matrix[u][v] = n + 1\n",
    "\n",
    "    for start in vertices_list:\n",
    "        V_to_calculate = set(vertices)\n",
    "        V_to_calculate.discard(start)\n",
    "        V_visited = set()\n",
    "        queue = [(start, 0)]\n",
    "        queued = set([start])\n",
    "        max_depth = 0\n",
    "        while queued and V_to_calculate:\n",
    "            u, depth = queue.pop(0)\n",
    "            max_depth = max(max_depth, depth)\n",
    "            queued.discard(u)\n",
    "            V_visited.add(u)\n",
    "            u_adjacent_to_visit = graph_static[u].difference(V_visited)\n",
    "            for v in u_adjacent_to_visit:\n",
    "                if v in V_to_calculate:\n",
    "                    distance = distance_matrix[start][v]\n",
    "                    if depth + 1 < distance:\n",
    "                        distance_matrix[start][v] = depth + 1\n",
    "                        distance_matrix[v][start] = depth + 1\n",
    "                        V_to_calculate.discard(v)\n",
    "                if v not in queued:\n",
    "                    queue.append((v, depth + 1))\n",
    "                    queued.add(v)\n",
    "    \n",
    "    for u in vertices_list:\n",
    "        for v in vertices_list:\n",
    "            if u > v:\n",
    "                distances.append(distance_matrix[u][v])\n",
    "    eccentricities = dict()\n",
    "    for u in distance_matrix:\n",
    "        eccentricities[u] = max(distance_matrix[u].values())\n",
    "\n",
    "    return (distance_matrix, eccentricities, distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diameter_from_random_500 = 8, radius_from_random_500 = 5, percentile_90_from_random_500 = 5.0\n",
      "diameter_from_random_1000 = 9, radius_from_random_1000 = 5, percentile_90_from_random_1000 = 4.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "component = list(connectivity_components[max_connectivity_component_index])\n",
    "\n",
    "random_500_vertices = sorted(random.sample(component, 500))\n",
    "random_1000_vertices = sorted(random.sample(component, 1000))\n",
    "\n",
    "random_500_matrix, random_500_eccentricities, random_500_distances = calculate_matrix(\n",
    "    random_500_vertices)\n",
    "random_1000_matrix, random_1000_eccentricities, random_1000_distances = calculate_matrix(\n",
    "    random_1000_vertices)\n",
    "\n",
    "diameter_from_random_500 = max(random_500_eccentricities.values())\n",
    "radius_from_random_500 = min(random_500_eccentricities.values())\n",
    "percentile_90_from_random_500 = np.percentile(random_500_distances, 90)\n",
    "\n",
    "print(f\"{diameter_from_random_500 = }, {radius_from_random_500 = }, {percentile_90_from_random_500 = }\")\n",
    "\n",
    "diameter_from_random_1000 = max(random_1000_eccentricities.values())\n",
    "radius_from_random_1000 = min(random_1000_eccentricities.values())\n",
    "percentile_90_from_random_1000 = np.percentile(random_1000_distances, 90)\n",
    "\n",
    "print(f\"{diameter_from_random_1000 = }, {radius_from_random_1000 = }, {percentile_90_from_random_1000 = }\")\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diameter_from_snowball_500 = 2, radius_from_snowball_500 = 1, percentile_90_from_snowball_500 = 2.0\n",
      "diameter_from_snowball_1000 = 4, radius_from_snowball_1000 = 2, percentile_90_from_snowball_1000 = 3.0\n"
     ]
    }
   ],
   "source": [
    "def snowball(limit):\n",
    "    vertices = {component[0], component[1]}\n",
    "    while len(vertices) < limit:\n",
    "        for v in vertices:\n",
    "            if len(vertices) < limit:\n",
    "                vertices = vertices.union(graph_static[v])\n",
    "    return sorted(list(vertices))\n",
    "\n",
    "snowball_500_vertices = snowball(500)\n",
    "snowball_1000_vertices = snowball(1000)\n",
    "\n",
    "snowball_500_matrix, snowball_500_eccentricities, snowball_500_distances = calculate_matrix(\n",
    "    snowball_500_vertices)\n",
    "snowball_1000_matrix, snowball_1000_eccentricities, snowball_1000_distances = calculate_matrix(\n",
    "    snowball_1000_vertices)\n",
    "\n",
    "diameter_from_snowball_500 = max(snowball_500_eccentricities.values())\n",
    "radius_from_snowball_500 = min(snowball_500_eccentricities.values())\n",
    "percentile_90_from_snowball_500 = np.percentile(snowball_500_distances, 90)\n",
    "\n",
    "print(f\"{diameter_from_snowball_500 = }, {radius_from_snowball_500 = }, {percentile_90_from_snowball_500 = }\")\n",
    "\n",
    "diameter_from_snowball_1000 = max(snowball_1000_eccentricities.values())\n",
    "radius_from_snowball_1000 = min(snowball_1000_eccentricities.values())\n",
    "percentile_90_from_snowball_1000 = np.percentile(snowball_1000_distances, 90)\n",
    "\n",
    "print(f\"{diameter_from_snowball_1000 = }, {radius_from_snowball_1000 = }, {percentile_90_from_snowball_1000 = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diameter = 10, raduis = 5, percentile_90 = 5\n"
     ]
    }
   ],
   "source": [
    "# 1.2\n",
    "print(\"diameter = %i, raduis = %i, percentile_90 = %i\" \n",
    "      % (diameter, radius, percentile_90))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "component = list(connectivity_components[max_connectivity_component_index])\n",
    "\n",
    "Cl = dict()\n",
    "for u in component:\n",
    "    u_neighbors = graph_static[u]\n",
    "\n",
    "    if len(u_neighbors) < 2:\n",
    "        Cl[u] = 0\n",
    "        continue\n",
    "\n",
    "    Lu_doubled = 0\n",
    "    for neighbor in u_neighbors:\n",
    "        Lu_doubled += len(graph_static[neighbor].intersection(u_neighbors))\n",
    "    Cl[u] = Lu_doubled / (len(u_neighbors) * (len(u_neighbors) - 1))\n",
    "\n",
    "Cl_average = sum(Cl.values()) / len(Cl.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cl_average = 0.177003\n"
     ]
    }
   ],
   "source": [
    "#1.3\n",
    "print(\"Cl_average = %f\" % (Cl_average))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "R1 = 0\n",
    "R2 = 0\n",
    "R3 = 0\n",
    "Re = 0\n",
    "for i in range(1, n + 1):\n",
    "    ki = len(graph_static[i])\n",
    "    R1 += ki\n",
    "    R2 += ki**2\n",
    "    R3 += ki**3\n",
    "    for j in graph_static[i]:\n",
    "        kj = len(graph_static[j])\n",
    "        Re += ki * kj\n",
    "degree_associativity = (Re * R1 - R2**2) / (R3 * R1 - R2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree associativity = -0.168516\n"
     ]
    }
   ],
   "source": [
    "print(\"Degree associativity = %f\" % (degree_associativity))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Static topological features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_static_topological_features():\n",
    "    CN_static = {}\n",
    "    AA_static = {}\n",
    "    JC_static = {}\n",
    "    PA_static = {}\n",
    "    \n",
    "    visited = set()\n",
    "    for u in V:\n",
    "        visited.add(u)\n",
    "        for v in graph_static[u]:\n",
    "            if v in visited:\n",
    "                continue\n",
    "            gamma_u = graph_static[u]\n",
    "            gamma_v = graph_static[v]\n",
    "            \n",
    "            intersection_u_v = gamma_u.intersection(gamma_v)\n",
    "            CN_static[(u, v)] = len(intersection_u_v)\n",
    "            JC_static[(u, v)] = CN_static[(u, v)] / len(gamma_u.union(gamma_v))\n",
    "            PA_static[(u, v)] = len(gamma_u) * len(gamma_v)\n",
    "            AA_static[(u, v)] = sum([1.0 / np.log(len(graph_static[z])) for z in intersection_u_v])\n",
    "    return CN_static, AA_static, JC_static, PA_static\n",
    "\n",
    "CN_static, AA_static, JC_static, PA_static = get_static_topological_features()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Node activity features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t_min = graph[\"_timestamp\"].min()\n",
    "t_max = graph[\"_timestamp\"].max()\n",
    "s = 2.0 / 3.0\n",
    "t_s = t_min + (t_max - t_min) * s\n",
    "l = 0.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 1: Temporal weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t_matrix = np.array([dict() for _ in range(n + 1)])\n",
    "for _index, _from, _to, _weight, _timestamp in graph.itertuples():\n",
    "    if _from == _to or _timestamp > t_s:\n",
    "        continue\n",
    "    \n",
    "    if t_matrix[_from].get(_to) is not None: \n",
    "        t_matrix[_from][_to].append(_timestamp)\n",
    "    else:\n",
    "        t_matrix[_from][_to] = [_timestamp]\n",
    "    \n",
    "    if t_matrix[_to].get(_from) is not None: \n",
    "        t_matrix[_to][_from].append(_timestamp)\n",
    "    else:\n",
    "        t_matrix[_to][_from] = [_timestamp]\n",
    "    \n",
    "    \n",
    "def get_temporal_weighting(l, t):\n",
    "    time_var = (t - t_min) / (t_s - t_min)\n",
    "    w_linear = l + (1 - l) * time_var\n",
    "    w_exponential = l + (1 - l) * (np.exp(3 * time_var) - 1) / (np.exp(3) - 1)\n",
    "    w_square_root = l + (1 - l) * np.sqrt(time_var)\n",
    "    return [w_linear, w_exponential, w_square_root]\n",
    "\n",
    "for vt in t_matrix:\n",
    "    for v, times in vt.items():\n",
    "        for i, t in enumerate(times):\n",
    "            vt[v][i] = get_temporal_weighting(l, t)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 2: Aggregation of node activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AggregationOfNodeActivity:  \n",
    "    @staticmethod\n",
    "    def zeroth_quantile(weights):\n",
    "        return np.quantile(weights, 0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def first_quantile(weights):\n",
    "        return np.quantile(weights, 0.25)\n",
    "    \n",
    "    @staticmethod\n",
    "    def second_quantile(weights):\n",
    "        return np.quantile(weights, 0.50)\n",
    "    \n",
    "    @staticmethod\n",
    "    def third_quantile(weights):\n",
    "        return np.quantile(weights, 0.75)\n",
    "    \n",
    "    @staticmethod\n",
    "    def fourth_quantile(weights):\n",
    "        return np.quantile(weights, 1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_sum(weights):\n",
    "        return sum(weights)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_mean(weights):\n",
    "        return np.mean(weights)\n",
    "    \n",
    "    @staticmethod\n",
    "    def aggregate(weights):\n",
    "        return [\n",
    "            AggregationOfNodeActivity.zeroth_quantile(weights),\n",
    "            AggregationOfNodeActivity.first_quantile(weights),\n",
    "            AggregationOfNodeActivity.second_quantile(weights),\n",
    "            AggregationOfNodeActivity.third_quantile(weights),\n",
    "            AggregationOfNodeActivity.fourth_quantile(weights),\n",
    "            AggregationOfNodeActivity.get_sum(weights),\n",
    "            AggregationOfNodeActivity.get_mean(weights)\n",
    "        ]\n",
    "\n",
    "\n",
    "node_activity_feature_graph = [list() for _ in range(len(t_matrix))]\n",
    "\n",
    "for ind, vt in enumerate(t_matrix):\n",
    "    if ind == 0 or len(vt) == 0:\n",
    "        continue\n",
    "    linears = []\n",
    "    exponentials = []\n",
    "    squares = []\n",
    "    for v, weights in vt.items():\n",
    "        if not linears:\n",
    "            linears = [w[0] for w in weights]\n",
    "            exponentials = [w[1] for w in weights]\n",
    "            squares = [w[2] for w in weights]\n",
    "            continue\n",
    "        linears.extend([w[0] for w in weights])\n",
    "        exponentials.extend([w[1] for w in weights])\n",
    "        squares.extend([w[2] for w in weights])\n",
    "    for weights in (linears, exponentials, squares):\n",
    "        node_activity_feature_graph[ind].extend(\n",
    "            AggregationOfNodeActivity.aggregate(weights)\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 3: Combining node activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CombiningNodeActivity:\n",
    "    @staticmethod\n",
    "    def get_sum(a, b):\n",
    "        return a + b\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_absolute_differrence(a, b):\n",
    "        return abs(a - b)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_minimum(a, b):\n",
    "        return min(a, b)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_maximum(a, b):\n",
    "        return max(a, b)\n",
    "    \n",
    "    @staticmethod\n",
    "    def combine(u_list, v_list):\n",
    "        feature = []\n",
    "        for a, b in zip(u_list, v_list):\n",
    "            feature.append(CombiningNodeActivity.get_sum(a, b))\n",
    "            feature.append(CombiningNodeActivity.get_absolute_differrence(a, b))\n",
    "            feature.append(CombiningNodeActivity.get_minimum(a, b))\n",
    "            feature.append(CombiningNodeActivity.get_maximum(a, b))\n",
    "        return feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = set()\n",
    "\n",
    "for u in range(1, n):\n",
    "    u_adj = set(t_matrix[u].keys())\n",
    "    for v in range(u + 1, n + 1):\n",
    "        if v in u_adj:\n",
    "            continue\n",
    "        v_adj = set(t_matrix[v].keys())\n",
    "        if v_adj.intersection(u_adj):\n",
    "            pairs.add((u, v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525 486481\n"
     ]
    }
   ],
   "source": [
    "connecting = list()\n",
    "non_connecting = list()\n",
    "\n",
    "for u, v in pairs:\n",
    "    if v in graph_static[u]:\n",
    "        connecting.append((u, v))\n",
    "    else:\n",
    "        non_connecting.append((u, v))\n",
    "\n",
    "print(len(connecting), len(non_connecting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10\n",
    "x_y = random.choices(connecting, k=m)\n",
    "x_n = random.choices(non_connecting, k=m)\n",
    "\n",
    "# all = train + test\n",
    "\n",
    "x_all_pairs = list(x_y)\n",
    "x_all_pairs.extend(x_n)\n",
    "\n",
    "y_all = [1] * m\n",
    "y_all.extend([0] * m)\n",
    "\n",
    "x_all = []\n",
    "features = dict.fromkeys(list(set(x_y).union(set(x_n))))\n",
    "for u, v in features.keys():\n",
    "    features[(u, v)] = CombiningNodeActivity.combine(\n",
    "        node_activity_feature_graph[u], node_activity_feature_graph[v]\n",
    "    )\n",
    "for pair in x_all_pairs:\n",
    "    x_all.append(features[pair])\n",
    "\n",
    "x_train = []\n",
    "x_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1289192400 1398690000.0 1453438800\n",
      "22115\n"
     ]
    }
   ],
   "source": [
    "counter1 = 0\n",
    "counter = 0\n",
    "print(t_min, t_s,t_max)\n",
    "for _index, _from, _to, _weight, _timestamp in graph.itertuples():\n",
    "    if _from == _to or _timestamp > t_s:\n",
    "        continue\n",
    "    counter += 1\n",
    "print(counter)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
