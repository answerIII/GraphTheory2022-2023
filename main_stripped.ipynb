{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 19428, volume = 96662\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "    \"test_graphs/socfb-Middlebury45.txt\",\n",
    "    \"test_graphs/socfb-Reed98.txt\",\n",
    "    \"test_graphs/testgraph_1.txt\",\n",
    "    \"test_graphs/testgraph_2.txt\",\n",
    "    \"test_graphs/testgraph_3.txt\",\n",
    "    \"test_graphs/testgraph_4.txt\",\n",
    "    \"test_graphs/testgraph_5.txt\",\n",
    "    \"test_graphs/testgraph_6.txt\",\n",
    "    \"test_graphs/testgraph_7.txt\",\n",
    "    \"test_graphs/team_11.txt\"\n",
    "]\n",
    "dataset_names = [\n",
    "    \"mid\",\n",
    "    \"reed\",\n",
    "    \"1\",\n",
    "    \"2\",\n",
    "    \"3\",\n",
    "    \"4\",\n",
    "    \"5\",\n",
    "    \"6\",\n",
    "    \"7\",\n",
    "    \"team\"\n",
    "]\n",
    "current = 8 # 0 - 9\n",
    "graph = pd.read_csv(\n",
    "    datasets[current],\n",
    "    names=[\"_from\", \"_to\"],\n",
    "    sep=\" |\\t\",\n",
    "    engine ='python',\n",
    ")\n",
    "V = np.unique(graph[\"_from\"]._append(graph[\"_to\"])).astype(int)\n",
    "V.sort()\n",
    "n = V.size\n",
    "volume = graph[\"_from\"].size\n",
    "print(f\"{n = }, {volume = }\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(lines: list[str]):\n",
    "    \"\"\"Writes results to .txt files.\n",
    "    Args:\n",
    "        number_of_task (int): 1 or 2.\n",
    "        lines (list[str]): Lines to write.\n",
    "    \"\"\"\n",
    "    with open(f\"test_results/dataset_{dataset_names[current]}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(line + '\\n' for line in lines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparing static graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "graph_static = dict.fromkeys(V)\n",
    "for u in V:\n",
    "    graph_static[u] = set()\n",
    "for _index, _from, _to in graph.itertuples():\n",
    "    if _from == _to:\n",
    "        continue\n",
    "    if not _to in V:\n",
    "        print(_from, _to)\n",
    "    graph_static[_from].add(_to)\n",
    "    graph_static[_to].add(_from)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 1.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### |E| and density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "E_count = 0\n",
    "for u in graph_static.keys():\n",
    "    E_count += len(graph_static[u])\n",
    "E_count //= 2\n",
    "#print(E_count)\n",
    "\n",
    "density = E_count * 2 / (n * (n - 1))\n",
    "#print(density)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectivity components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "V_to_visit = set(V)\n",
    "connectivity_components = []\n",
    "while(V_to_visit):\n",
    "    V_seen = set()\n",
    "    queue = []\n",
    "    for u in V_to_visit:\n",
    "        queue.append(u)\n",
    "        V_seen.add(u)\n",
    "        break\n",
    "    while queue:\n",
    "        u = queue.pop()\n",
    "        u_adjacent_to_visit = graph_static[u].difference(V_seen)\n",
    "        for v in u_adjacent_to_visit:\n",
    "            V_seen.add(v)\n",
    "            queue.append(v)\n",
    "    V_to_visit = V_to_visit.difference(V_seen)\n",
    "    connectivity_components.append(V_seen)\n",
    "\n",
    "sizes = list(map(lambda x: len(x), connectivity_components))\n",
    "max_component_size = max(sizes)\n",
    "max_connectivity_component_index = sizes.index(max_component_size)\n",
    "proportion = max_component_size / len(V)\n",
    "#print(f\"{max_val = }, {max_connectivity_component_index = }, {proportion = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|V| = 19428, |E| = 96662, p = 0.000512, number of components = 23, max component size = 19365, max component proportion = 0.996757\n"
     ]
    }
   ],
   "source": [
    "# 1.1\n",
    "print(\"|V| = %i, |E| = %i, p = %f, number of components = %i, max component size = %i, max component proportion = %f\"\n",
    "      % (n, E_count, density, len(connectivity_components), max_component_size, proportion))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 1.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diameter, radius, all distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187491930 = 187491930 True\n"
     ]
    }
   ],
   "source": [
    "component = list(connectivity_components[max_connectivity_component_index])\n",
    "distances = [0] * (n + 2)\n",
    "diameter = 0\n",
    "radius = n + 1\n",
    "n_limit = 20000\n",
    "if n < n_limit:\n",
    "    for start in component:\n",
    "        distances_tmp = dict.fromkeys(V, n + 1)\n",
    "        V_visited = set()\n",
    "        queue = [(start, 0)]\n",
    "        queued = set([start])\n",
    "        depth = 0\n",
    "        u = start\n",
    "        while queued:\n",
    "            (u, depth) = queue.pop(0)\n",
    "            queued.remove(u)\n",
    "            V_visited.add(u)\n",
    "            u_adjacent_to_visit = graph_static[u].difference(V_visited)\n",
    "            for v in u_adjacent_to_visit:\n",
    "                distances_tmp[v] = min(distances_tmp[v], depth + 1)\n",
    "                if v not in queued:\n",
    "                    queue.append((v, depth + 1))\n",
    "                    queued.add(v)\n",
    "        for u in V:\n",
    "            if u > start:\n",
    "                distances[distances_tmp[u]] += 1\n",
    "        diameter = max(diameter, depth)\n",
    "        radius = min(radius, depth)\n",
    "        if not start % 10:\n",
    "            #print(start, \"/\", n)\n",
    "            pass\n",
    "all_dist = 0\n",
    "for i in range(diameter + 1):\n",
    "    all_dist += distances[i]\n",
    "print(all_dist, \"=\", max_component_size * (max_component_size - 1) // 2,\n",
    "      all_dist == max_component_size * (max_component_size - 1) // 2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 90 percentille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#percentile_90 = np.percentile(all_distances, 90)\n",
    "percentile_90_ind = int(0.9 * all_dist)\n",
    "percentile_90 = 0\n",
    "ind_tmp = 0\n",
    "for i in range(diameter + 1):\n",
    "    ind_tmp += distances[i]\n",
    "    if ind_tmp >= percentile_90_ind:\n",
    "        percentile_90 = i\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance matrix for a set of vertices function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_matrix(vertices):\n",
    "\n",
    "    vertices_list = list(vertices)\n",
    "\n",
    "    distances = []\n",
    "    distance_matrix = dict()\n",
    "    for u in vertices_list:\n",
    "        distance_matrix[u] = dict()\n",
    "        for v in vertices_list:\n",
    "            if u != v:\n",
    "                distance_matrix[u][v] = n + 1\n",
    "\n",
    "    for start in vertices_list:\n",
    "        V_to_calculate = set(vertices)\n",
    "        V_to_calculate.discard(start)\n",
    "        V_visited = set()\n",
    "        queue = [(start, 0)]\n",
    "        queued = set([start])\n",
    "        max_depth = 0\n",
    "        while queued and V_to_calculate:\n",
    "            u, depth = queue.pop(0)\n",
    "            max_depth = max(max_depth, depth)\n",
    "            queued.discard(u)\n",
    "            V_visited.add(u)\n",
    "            u_adjacent_to_visit = graph_static[u].difference(V_visited)\n",
    "            for v in u_adjacent_to_visit:\n",
    "                if v in V_to_calculate:\n",
    "                    distance = distance_matrix[start][v]\n",
    "                    if depth + 1 < distance:\n",
    "                        distance_matrix[start][v] = depth + 1\n",
    "                        distance_matrix[v][start] = depth + 1\n",
    "                        V_to_calculate.discard(v)\n",
    "                if v not in queued:\n",
    "                    queue.append((v, depth + 1))\n",
    "                    queued.add(v)\n",
    "    \n",
    "    for u in vertices_list:\n",
    "        for v in vertices_list:\n",
    "            if u > v:\n",
    "                distances.append(distance_matrix[u][v])\n",
    "    eccentricities = dict()\n",
    "    for u in distance_matrix:\n",
    "        eccentricities[u] = max(distance_matrix[u].values())\n",
    "\n",
    "    return (distance_matrix, eccentricities, distances)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diameter, radius, percentille from vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diameter_from_random_500 = 10, radius_from_random_500 = 6, percentile_90_from_random_500 = 6.0\n"
     ]
    }
   ],
   "source": [
    "component = list(connectivity_components[max_connectivity_component_index])\n",
    "diameter_from_random_500 = 0\n",
    "radius_from_random_500 = 0\n",
    "percentile_90_from_random_500 = 0\n",
    "if n >= 500:\n",
    "    random_500_vertices = sorted(random.sample(component, 500))\n",
    "    random_500_matrix, random_500_eccentricities, random_500_distances = calculate_matrix(\n",
    "        random_500_vertices)\n",
    "    diameter_from_random_500 = max(random_500_eccentricities.values())\n",
    "    radius_from_random_500 = min(random_500_eccentricities.values())\n",
    "    percentile_90_from_random_500 = np.percentile(random_500_distances, 90)\n",
    "    print(f\"{diameter_from_random_500 = }, {radius_from_random_500 = }, {percentile_90_from_random_500 = }\")\n",
    "\n",
    "def snowball(limit, component):\n",
    "    vertices = set(random.sample(component, 2))\n",
    "    while len(vertices) < limit:\n",
    "        for v in vertices:\n",
    "            if len(vertices) < limit:\n",
    "                vertices = vertices.union(graph_static[v])\n",
    "    return sorted(list(vertices))\n",
    "\n",
    "diameter_from_snowball_500 = 0\n",
    "radius_from_snowball_500 = 0\n",
    "percentile_90_from_snowball_500 = 0\n",
    "if n >= 500:\n",
    "    snowball_500_vertices = snowball(500, component)\n",
    "    snowball_500_matrix, snowball_500_eccentricities, snowball_500_distances = calculate_matrix(\n",
    "        snowball_500_vertices)\n",
    "    diameter_from_snowball_500 = max(snowball_500_eccentricities.values())\n",
    "    radius_from_snowball_500 = min(snowball_500_eccentricities.values())\n",
    "    percentile_90_from_snowball_500 = np.percentile(snowball_500_distances, 90)\n",
    "    print(f\"{diameter_from_snowball_500 = }, {radius_from_snowball_500 = }, {percentile_90_from_snowball_500 = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diameter = 11, raduis = 6, percentile_90 = 6\n"
     ]
    }
   ],
   "source": [
    "# 1.2\n",
    "print(\"diameter = %i, raduis = %i, percentile_90 = %i\" \n",
    "      % (diameter, radius, percentile_90))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "component = list(connectivity_components[max_connectivity_component_index])\n",
    "\n",
    "Cl = dict()\n",
    "for u in component:\n",
    "    u_neighbors = graph_static[u]\n",
    "\n",
    "    if len(u_neighbors) < 2:\n",
    "        Cl[u] = 0\n",
    "        continue\n",
    "\n",
    "    Lu_doubled = 0\n",
    "    for neighbor in u_neighbors:\n",
    "        Lu_doubled += len(graph_static[neighbor].intersection(u_neighbors))\n",
    "    Cl[u] = Lu_doubled / (len(u_neighbors) * (len(u_neighbors) - 1))\n",
    "\n",
    "Cl_average = sum(Cl.values()) / len(Cl.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cl_average = 0.000000\n"
     ]
    }
   ],
   "source": [
    "#1.3\n",
    "print(\"Cl_average = %f\" % (Cl_average))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "R1 = 0\n",
    "R2 = 0\n",
    "R3 = 0\n",
    "Re = 0\n",
    "for u in V:\n",
    "    ku = len(graph_static[u])\n",
    "    R1 += ku\n",
    "    R2 += ku**2\n",
    "    R3 += ku**3\n",
    "    for v in graph_static[u]:\n",
    "        kv = len(graph_static[v])\n",
    "        Re += ku * kv\n",
    "degree_associativity = (Re * R1 - R2**2) / (R3 * R1 - R2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree associativity = -0.191557\n"
     ]
    }
   ],
   "source": [
    "print(\"Degree associativity = %f\" % (degree_associativity))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t_matrix = dict.fromkeys(V)\n",
    "for u in V:\n",
    "    t_matrix[u] = dict()\n",
    "\n",
    "for _index, _from, _to in graph.itertuples():\n",
    "    if _from == _to:\n",
    "        continue\n",
    "    t_matrix[_from][_to] = 1\n",
    "    t_matrix[_to][_from] = 1\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static features functions definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_static_topological_features(u, v):\n",
    "    gamma_u = set(t_matrix[u].keys())\n",
    "    gamma_v = set(t_matrix[v].keys())\n",
    "    \n",
    "    intersection_u_v = gamma_u.intersection(gamma_v)\n",
    "    \n",
    "    CN_static = len(intersection_u_v)\n",
    "    JC_static = CN_static / len(gamma_u.union(gamma_v))\n",
    "    PA_static = len(gamma_u) * len(gamma_v)\n",
    "    AA_static = sum(\n",
    "        [1.0 / np.log(len(set(t_matrix[z].keys()))) for z in intersection_u_v]\n",
    "    )\n",
    "    return CN_static, AA_static, JC_static, PA_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = get_static_topological_features(1, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing results down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [\n",
    "    \"Task 1.1\",\n",
    "    f\"Число вершин: |V| = {n}\",\n",
    "    f\"Число ребер: |E| = {E_count}\",\n",
    "    f\"Плотность: p = {density}\",\n",
    "    f\"Число компонент слабой связности: {len(connectivity_components)}\",\n",
    "    f\"Доля вершин в максимальной по мощности компоненте слабой связности: {proportion}\",\n",
    "    \"\\nTask 1.2\",\n",
    "    f\"Оценки для 500 вершин (случайные вершины): {diameter_from_random_500 = }, {radius_from_random_500 = }, {percentile_90_from_random_500 = }\",\n",
    "    f\"Оценки для 500 вершин (снежный ком): {diameter_from_snowball_500 = }, {radius_from_snowball_500 = }, {percentile_90_from_snowball_500 = }\",\n",
    "    f\"Вычисленные значения: {diameter = }, {radius = }, {percentile_90 = }\" if n < n_limit else \"Для этого датасета диаметр, радиус и 90-ый перцентиль будут вычисляться долго\",\n",
    "    \"\\nTask 1.3\",\n",
    "    f\"Cредний кластерный коэффициент сети: {Cl_average = }\",\n",
    "    \"\\nTask 1.4\",\n",
    "    f\"Коэффициент корреляции Пирсона: {degree_associativity}\",\n",
    "    \"\\nTask 2\",\n",
    "    f\"Feature Vector [CN AA JC PA]: {feature}\"\n",
    "]\n",
    "write_results(lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
