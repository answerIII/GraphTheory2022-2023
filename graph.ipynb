{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f95250f-8450-4de1-a3bf-69ed04c8fd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import weakref\n",
    "from dataclasses import dataclass\n",
    "from itertools import takewhile\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.typing import ArrayLike\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, u_id: int, neighbors: ArrayLike, skip_unique: False = False):\n",
    "        self._u_id = u_id\n",
    "        # produces sorted array\n",
    "        self.neighbors = np.unique(neighbors) if not skip_unique else neighbors\n",
    "        \n",
    "    @property\n",
    "    def u_id(self):\n",
    "        return self._u_id\n",
    "    \n",
    "    @property\n",
    "    def deg(self):\n",
    "        return len(self.neighbors)\n",
    "    \n",
    "    def subgraph(self, other_nodes: np.ndarray):\n",
    "        return Node(self.u_id, get_intersection(self.neighbors, other_nodes), skip_unique=True)\n",
    "    \n",
    "    # def two_steps_neighbors(self):\n",
    "        \n",
    "\n",
    "class Network:\n",
    "    def __init__(self, path: str):\n",
    "        if not os.path.isfile(path):\n",
    "            raise OSError(\"wrong graph path\")\n",
    "        \n",
    "        with open(path) as f:\n",
    "            skip_rows = len(list(\n",
    "                takewhile(lambda s: s.startswith(\"%\"), f)\n",
    "            ))\n",
    "                \n",
    "        self.data = pd.read_csv(path, sep=r'\\s+', header=None,\n",
    "                                names=[\"fr\", \"to\", \"weight\", \"timestamp\"], skiprows=skip_rows)\\\n",
    "                        .drop(columns=[\"weight\"])\\\n",
    "                        .sort_values(by=\"timestamp\")\n",
    "        \n",
    "        self.edges = np.sort(self.data[[\"fr\", \"to\"]].values)\n",
    "        self.total_nodes = self.edges.max()\n",
    "        self.timestamps = self.data.timestamp.values\n",
    "\n",
    "    def __str__(self):\n",
    "        ans = \"from\\tto\\tweight\\ttimestamp\\n\"\n",
    "\n",
    "        for key in sorted(self.__graph.keys()):\n",
    "            node = self.__graph[key]\n",
    "\n",
    "            for j in node.edges_to:\n",
    "                ans += f\"{node.u_id}\\t{j.node.u_id}\\n\"\n",
    "\n",
    "        return ans\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, network: Network, edges: np.ndarray, nodes: dict[int, Node]):\n",
    "        self.network = network\n",
    "        self.edges = edges\n",
    "        self.edges_set: np.ndarray = np.unique(self.edges, axis=0)\n",
    "        self.nodes = nodes\n",
    "    \n",
    "    def get_subgraph(self, nodes_ids: ArrayLike) -> \"Graph\":\n",
    "        nodes_ids = np.unique(nodes_ids)\n",
    "        new_nodes = {u_id : self.nodes[u_id].subgraph(nodes_ids)\n",
    "                     for u_id in nodes_ids}\n",
    "        new_edges = np.array([\n",
    "            [u_id, neighbor] for u_id, node in new_nodes.items() for neighbor in node.neighbors\n",
    "        ])\n",
    "        \n",
    "        return Graph(self.network, new_edges, new_nodes)\n",
    "    \n",
    "    @property\n",
    "    def density(self):\n",
    "        if len(self.nodes) > 1:\n",
    "            return 2 * len(self.edges_set) / len(self.nodes) / (len(self.nodes) - 1) \n",
    "        return np.nan\n",
    "\n",
    "class StaticGraph(Graph):\n",
    "    def __init__(self, timestamps, *args, **kwargs):\n",
    "        self.timestamps = timestamps\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    @staticmethod\n",
    "    def from_time_slice(network, quantile_end, quantile_start=0) -> \"Graph\":\n",
    "        assert 0 <= quantile_start <= quantile_end <= 1, \"Incorrect quantiles\"\n",
    "        \n",
    "        timestamps = network.timestamps\n",
    "        left, right = np.quantile(timestamps, [quantile_start, quantile_end])\n",
    "        mask = (left <= timestamps) & (timestamps <= right)\n",
    "        edges = network.edges[mask]\n",
    "        timestamps = timestamps[mask]\n",
    "        \n",
    "        undirected = np.vstack([edges, edges[:, ::-1]])\n",
    "        adj_lists = pd.DataFrame(undirected, columns=[\"v1\", \"v2\"])\\\n",
    "            .groupby(\"v1\")\\\n",
    "            .v2.apply(np.array)\n",
    "        \n",
    "        nodes = {u_id : Node(u_id, neighbors) for u_id, neighbors in adj_lists.items()}\n",
    "        \n",
    "        return StaticGraph(timestamps, network, edges, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4351569-1f41-479c-8764-40f5290cbd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def get_intersection(first, second):\n",
    "    i = j = k = 0\n",
    "    buffer = np.empty(min(first.size, second.size), dtype=first.dtype)\n",
    "    while i < first.size and j < second.size:\n",
    "        if first[i] == second[j]:\n",
    "            buffer[k] = first[i]\n",
    "            k += 1\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif first[i] < second[j]:\n",
    "            i += 1\n",
    "        else: \n",
    "            j += 1\n",
    "    return buffer[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac09334e-edcc-4483-8899-996c3ed902b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network(\"data/opsahl-ucsocial/out.opsahl-ucsocial\")\n",
    "time_quantile = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b49c94c-2d5a-4f19-8d73-04c26e15d61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StaticGraph.from_time_slice(network, time_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "682ad119-b0c9-41ed-8b8e-911c36224538",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vertices = len(graph.nodes)\n",
    "num_edges = len(graph.edges_set)\n",
    "density = 2 * num_edges / num_vertices / (num_vertices - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74cf05c6-bebc-433a-956a-c8c54fab02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import deque\n",
    "\n",
    "def get_connected_comps(graph: Graph) -> list[list[int]]:\n",
    "    visited = {u_id : False for u_id in graph.nodes}\n",
    "    queue = deque(graph.nodes)\n",
    "    conn_comps: list[list[int]] = []\n",
    "    \n",
    "    for root_u_id in graph.nodes.keys():\n",
    "        if visited[root_u_id]:\n",
    "            continue\n",
    "            \n",
    "        queue = deque([root_u_id])\n",
    "        conn_comps.append([])\n",
    "        \n",
    "        while queue:\n",
    "            u_id = queue.popleft()\n",
    "            conn_comps[-1].append(u_id)\n",
    "            if not visited[u_id]:\n",
    "                for neighbor_id in graph.nodes[u_id].neighbors:\n",
    "                    if not visited[neighbor_id]:\n",
    "                        queue.append(neighbor_id)\n",
    "                        visited[neighbor_id] = True\n",
    "    return conn_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d81d37d-cddc-42cd-b349-44ee1e3d35d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_comps = get_connected_comps(graph)\n",
    "conn_comp = graph.get_subgraph(max(conn_comps, key=len))\n",
    "max_conn_comp_fraction =  len(conn_comp.nodes) / num_vertices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d1ecac8-846e-48f8-b1e6-ce09da00173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr \n",
    "\n",
    "def get_avg_cluster_coeff(graph: Graph) -> float:\n",
    "    return np.nanmean([graph.get_subgraph(node.neighbors).density\n",
    "                       for node in graph.nodes.values()])\n",
    "\n",
    "def get_deg_assortivity(graph: Graph) -> float:\n",
    "    degs = np.vectorize(lambda node_id: graph.nodes[node_id].deg)(graph.edges_set)\n",
    "    return pearsonr(degs[:, 0], degs[:, 1]).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9338180c-8f34-4d6b-a5fb-40f502f8bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e737c142-afd2-4fc2-99e1-915be8767a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_static_features(graph):\n",
    "    size = graph.network.total_nodes + 1\n",
    "    intersections = np.zeros((size, size))\n",
    "    aa = np.zeros((size, size))\n",
    "    degs = np.zeros(size)\n",
    "    \n",
    "    for node in graph.nodes.values():\n",
    "        degs[node.u_id] = node.deg\n",
    "        if node.deg > 1:\n",
    "            intersections[np.ix_(node.neighbors, node.neighbors)] += 1\n",
    "            aa[np.ix_(node.neighbors, node.neighbors)] += 1 / np.log(node.deg)\n",
    "        \n",
    "    # unions are needed for jaccard, thus need to add something to zeros\n",
    "    unions = degs.reshape(-1, 1) + degs.reshape(1, -1) - intersections\n",
    "    unions[unions == 0] = 1\n",
    "    \n",
    "    features = np.dstack([\n",
    "        intersections,\n",
    "        aa,\n",
    "        intersections / unions,\n",
    "        degs.reshape(-1, 1) * degs.reshape(1, -1),\n",
    "    ])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ad7a1ba-e6b7-495e-972d-df8318bf39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def post_event_agg(weights: np.ndarray):\n",
    "    return np.array([\n",
    "        *np.quantile(weights, [0, .25, .5, .75, 1]),\n",
    "        weights.sum(),\n",
    "        weights.mean(),\n",
    "        weights.var()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7950133e-0fe7-4b35-bdc8-41d9860aeeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-6\n",
    "\n",
    "def get_features(graph: StaticGraph, lower_bound: float):\n",
    "    t = graph.timestamps\n",
    "    dt = (t - t.min()) / (t.max() - t.min())\n",
    "    weights = lower_bound + (1 - lower_bound) * np.vstack([\n",
    "        dt,\n",
    "        (np.exp(3 * dt) - 1) / (np.exp(3) - 1),\n",
    "        np.sqrt(dt)\n",
    "    ]).T\n",
    "    \n",
    "    edges_weights = pd.concat([\n",
    "        pd.DataFrame(graph.edges, columns=[\"v1\", \"v2\"]),\n",
    "        pd.DataFrame(weights, columns=[\"w1\", \"w2\", \"w3\"])\n",
    "    ], axis=1)\\\n",
    "        .groupby([\"v1\", \"v2\"])\\\n",
    "        [[\"w1\", \"w2\", \"w3\"]]\\\n",
    "        .agg(pd.Series.to_list)\\\n",
    "        .applymap(np.array)\\\n",
    "        .applymap(post_event_agg)\\\n",
    "        .apply(lambda row: np.concatenate(row.values), axis=1)\n",
    "    \n",
    "    size = graph.network.total_nodes + 1\n",
    "    features = np.zeros((size, size, 24))\n",
    "    summs = np.zeros((size, size, 24))\n",
    "    aa = np.zeros((size, size, 24))\n",
    "    outgoing_sums = np.zeros((size, 24))\n",
    "    \n",
    "    features[*zip(*edges_weights.index), :] = np.vstack(edges_weights)\n",
    "    \n",
    "    for node in graph.nodes.values():\n",
    "        node_features = features[node.u_id, node.neighbors]\n",
    "        \n",
    "        if node.deg > 1:\n",
    "            t_summs = node_features[None, :] + node_features[:, None]\n",
    "            summs[np.ix_(node.neighbors, node.neighbors)] = t_summs\n",
    "            outgoing_sums[node.u_id] = node_features.sum(axis=0)\n",
    "            aa[np.ix_(node.neighbors, node.neighbors)] = t_summs / np.log(1 + outgoing_sums[node.u_id] + EPS)\n",
    "    \n",
    "    out_features = np.dstack([\n",
    "        aa, # AA\n",
    "        summs, # CN\n",
    "        summs / (outgoing_sums[None, :] + outgoing_sums[:, None] + EPS), # JC\n",
    "        outgoing_sums[None, :] * outgoing_sums[:, None], # PA\n",
    "    ])\n",
    "\n",
    "    return out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4121d4c1-e81a-44b7-9923-16f95cabb15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = get_features(graph, .2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "a1b8bd91-2d48-41f0-985f-f3a4a3e9252f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1900, 1900, 96)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
