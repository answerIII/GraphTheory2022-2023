{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f95250f-8450-4de1-a3bf-69ed04c8fd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import weakref\n",
    "from dataclasses import dataclass\n",
    "from itertools import takewhile\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "from numpy.typing import ArrayLike\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, u_id: int, neighbors: ArrayLike, skip_unique: False = False):\n",
    "        self._u_id = u_id\n",
    "        # produces sorted array\n",
    "        self.neighbors = np.unique(neighbors) if not skip_unique else neighbors\n",
    "        \n",
    "    @property\n",
    "    def u_id(self):\n",
    "        return self._u_id\n",
    "    \n",
    "    @property\n",
    "    def deg(self):\n",
    "        return len(self.neighbors)\n",
    "    \n",
    "    def subgraph(self, other_nodes: np.ndarray):\n",
    "        return Node(self.u_id, get_intersection(self.neighbors, other_nodes), skip_unique=True)\n",
    "    \n",
    "\n",
    "class Network:\n",
    "    def __init__(self, path: str):\n",
    "        if not os.path.isfile(path):\n",
    "            raise OSError(\"wrong graph path\")\n",
    "        \n",
    "        with open(path) as f:\n",
    "            skip_rows = len(list(\n",
    "                takewhile(lambda s: s.startswith(\"%\"), f)\n",
    "            ))\n",
    "                \n",
    "        self.data = pd.read_csv(path, sep=r'\\s+', header=None,\n",
    "                                names=[\"fr\", \"to\", \"weight\", \"timestamp\"], skiprows=skip_rows)\\\n",
    "                        .drop(columns=[\"weight\"])\\\n",
    "                        .sort_values(by=\"timestamp\")\n",
    "        \n",
    "        self.edges = np.sort(self.data[[\"fr\", \"to\"]].values)\n",
    "        self.total_nodes = self.edges.max()\n",
    "        self.timestamps = self.data.timestamp.values\n",
    "\n",
    "    def __str__(self):\n",
    "        ans = \"from\\tto\\tweight\\ttimestamp\\n\"\n",
    "\n",
    "        for key in sorted(self.__graph.keys()):\n",
    "            node = self.__graph[key]\n",
    "\n",
    "            for j in node.edges_to:\n",
    "                ans += f\"{node.u_id}\\t{j.node.u_id}\\n\"\n",
    "\n",
    "        return ans\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, network: Network, edges: np.ndarray, nodes: dict[int, Node]):\n",
    "        self.network = network\n",
    "        self.edges = edges\n",
    "        self.edges_set: np.ndarray = np.unique(self.edges, axis=0)\n",
    "        self.nodes = nodes\n",
    "    \n",
    "    def get_subgraph(self, nodes_ids: ArrayLike) -> \"Graph\":\n",
    "        nodes_ids = np.unique(nodes_ids)\n",
    "        new_nodes = {u_id : self.nodes[u_id].subgraph(nodes_ids)\n",
    "                     for u_id in nodes_ids}\n",
    "        new_edges = np.array([\n",
    "            [u_id, neighbor] for u_id, node in new_nodes.items() for neighbor in node.neighbors\n",
    "        ])\n",
    "        \n",
    "        return Graph(self.network, new_edges, new_nodes)\n",
    "    \n",
    "    @property\n",
    "    def density(self):\n",
    "        if len(self.nodes) > 1:\n",
    "            return 2 * len(self.edges_set) / len(self.nodes) / (len(self.nodes) - 1) \n",
    "        return np.nan\n",
    "\n",
    "class StaticGraph(Graph):\n",
    "    def __init__(self, timestamps, quantile_end, *args, **kwargs):\n",
    "        self.timestamps = timestamps\n",
    "        self.quantile_end = quantile_end\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    @staticmethod\n",
    "    def from_time_slice(network, quantile_end, quantile_start=0) -> \"Graph\":\n",
    "        assert 0 <= quantile_start <= quantile_end <= 1, \"Incorrect quantiles\"\n",
    "        \n",
    "        timestamps = network.timestamps\n",
    "        left, right = np.quantile(timestamps, [quantile_start, quantile_end])\n",
    "        mask = (left <= timestamps) & (timestamps <= right)\n",
    "        edges = network.edges[mask]\n",
    "        timestamps = timestamps[mask]\n",
    "        \n",
    "        undirected = np.vstack([edges, edges[:, ::-1]])\n",
    "        adj_lists = pd.DataFrame(undirected, columns=[\"v1\", \"v2\"])\\\n",
    "            .groupby(\"v1\")\\\n",
    "            .v2.apply(np.array)\n",
    "        \n",
    "        nodes = {u_id : Node(u_id,np.empty(0, dtype=int)) for u_id in np.arange(1, network.total_nodes + 1)}\n",
    "        nodes |= {u_id : Node(u_id, neighbors) for u_id, neighbors in adj_lists.items()}\n",
    "        \n",
    "        return StaticGraph(timestamps, quantile_end, network, edges, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70486c71-e8d2-444c-aaa2-a26017f12150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_pairs(current_graph: StaticGraph, future_graph: StaticGraph):\n",
    "    has_link = []\n",
    "    no_link = []\n",
    "    \n",
    "    visited = np.zeros(len(current_graph.nodes) + 1, dtype=bool)\n",
    "    for node in current_graph.nodes.values():\n",
    "        if node.deg <= 1:\n",
    "            continue\n",
    "        \n",
    "        visited[np.concatenate([current_graph.nodes[neighbor_id].neighbors\n",
    "                                for neighbor_id in node.neighbors])] = True\n",
    "        visited[node.u_id] = False\n",
    "        intersection = get_intersection(future_graph.nodes[node.u_id].neighbors, visited.nonzero()[0]).astype(int)\n",
    "        has_link.append(np.vstack([np.full_like(intersection, node.u_id), intersection]))\n",
    "        visited[intersection] = False\n",
    "        \n",
    "        no_link_t = visited.nonzero()[0]\n",
    "        no_link.append(np.vstack([np.full_like(no_link_t, node.u_id), no_link_t]))\n",
    "        visited[no_link_t] = False\n",
    "    has_link, no_link = [np.hstack(arrs).T for arrs in [has_link, no_link]]\n",
    "    return has_link, no_link\n",
    "\n",
    "def get_train_set(graph: StaticGraph, seed: int = 42, size: int = 10_000):\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    \n",
    "    future_graph = StaticGraph.from_time_slice(graph.network, 1, graph.quantile_end)\n",
    "    has_link, no_link = get_all_pairs(graph, future_graph)\n",
    "    train_edges = np.hstack([\n",
    "        np.vstack([\n",
    "            has_link[rng.choice(len(has_link), size)],\n",
    "            no_link[rng.choice(len(no_link), size)]\n",
    "        ]),\n",
    "        np.repeat([1, 0], size).reshape(-1, 1)\n",
    "    ])\n",
    "    return train_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "177a553e-6607-4be0-bd15-9af46ac43c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_static_features_for_pair(first_neighbors, second_neighbors, degrees):\n",
    "    intersection = get_intersection(first_neighbors, second_neighbors)\n",
    "    first_deg, second_deg = first_neighbors.size, second_neighbors.size\n",
    "    return np.array([\n",
    "        intersection.size, # CN\n",
    "        (1 / np.log(degrees[intersection])).sum(), # AA\n",
    "        intersection.size / (first_deg + second_deg - intersection.size), ## JC\n",
    "        first_deg * second_deg # PA\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da31215d-12a6-41c5-9b2a-c32a392209fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_static_features(graph: StaticGraph, edges: np.ndarray):\n",
    "    ids = list(graph.nodes.keys())\n",
    "    degrees_raw = [node.deg for node in graph.nodes.values()]\n",
    "    \n",
    "    degrees = np.zeros(graph.network.total_nodes + 1)\n",
    "    degrees[ids] = degrees_raw\n",
    "    \n",
    "    features = np.vstack([\n",
    "        get_static_features_for_pair(\n",
    "            graph.nodes[first_id].neighbors, graph.nodes[second_id].neighbors,\n",
    "            degrees\n",
    "        ) for first_id, second_id, *_ in edges\n",
    "    ])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2f731f6-324a-47e4-8293-7db8b46eae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def _feat(weight):\n",
    "    return np.array([\n",
    "            *np.quantile(weight, [0, .25, .5, .75, 1]),\n",
    "            weight.sum(),\n",
    "            weight.mean(),\n",
    "            weight.var()\n",
    "    ])\n",
    "\n",
    "@njit\n",
    "def _post_event_agg(time: np.ndarray, t_min: float, t_max: float, lower_bound: float):\n",
    "    dt = (time - t_min) / (t_max - t_min)\n",
    "    weights = lower_bound + (1 - lower_bound) * np.vstack((\n",
    "        dt,\n",
    "        (np.exp(3 * dt) - 1) / (np.exp(3) - 1),\n",
    "        np.sqrt(dt)\n",
    "    ))\n",
    "    return np.concatenate((_feat(weights[0]), _feat(weights[1]), _feat(weights[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7950133e-0fe7-4b35-bdc8-41d9860aeeaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPS = 1e-6\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def _get_wtfs(indices: list[tuple], df, computed: dict[tuple[int, int], np.ndarray],\n",
    "             t_max: float, t_min: float, lower_bound: float):\n",
    "    for index in indices:\n",
    "        if index[0] > index[1]:\n",
    "            index = index[::-1]\n",
    "            \n",
    "        if index not in computed:\n",
    "            computed[index] = computed[index[::-1]] = \\\n",
    "                _post_event_agg(df[index], t_max, t_min, lower_bound)\n",
    "            \n",
    "    return np.vstack(list(map(computed.get, indices)))\n",
    "\n",
    "def _sum_outgoing_wtf(node_id, **params):\n",
    "    edges = [(node_id, neighbor_id) for neighbor_id in graph.nodes[node_id].neighbors]\n",
    "    return sum(_get_wtfs(indices=edges, **params), start=np.zeros(24))\n",
    "\n",
    "def _get_temporal_features_for_pair(graph, node_1_id, node_2_id, **params):\n",
    "    intersection = get_intersection(graph.nodes[node_1_id].neighbors, graph.nodes[node_2_id].neighbors)\n",
    "    # print([(node_1_id, inters) for inters in intersection])\n",
    "    # print([(node_2_id, inters) for inters in intersection])\n",
    "    wtf_sums = _get_wtfs(indices=[(node_1_id, inters) for inters in intersection], **params) + \\\n",
    "               _get_wtfs(indices=[(node_2_id, inters) for inters in intersection], **params)\n",
    "    \n",
    "    intersection_sum = np.vstack([_sum_outgoing_wtf(node_id=inters, **params)\n",
    "                                  for inters in intersection])\n",
    "    wtf_sum_node_1, wtf_sum_node_2  = [_sum_outgoing_wtf(node_id, **params) \n",
    "                                       for node_id in [node_1_id, node_2_id]]\n",
    "    \n",
    "    return np.concatenate([\n",
    "        (wtf_sums / np.log(1 + EPS + intersection_sum)).sum(axis=0), # AA\n",
    "        wtf_sums.sum(axis=0), # CN\n",
    "        wtf_sums.sum(axis=0) / (wtf_sum_node_1 + wtf_sum_node_2 + EPS), # JC\n",
    "        wtf_sum_node_1 * wtf_sum_node_2, # PA\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b8984de-8b69-46de-8a3a-4581a968be4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_temporal_features(graph: StaticGraph, edges: np.ndarray, lower_bound):\n",
    "    grouped = pd.DataFrame({\"v1\": graph.edges[:, 0], \"v2\": graph.edges[:, 1], \"time\": graph.timestamps})\\\n",
    "        .groupby([\"v1\", \"v2\"])\\\n",
    "        [\"time\"].apply(np.array)\n",
    "    \n",
    "    computed: dict[tuple[int, int], np.ndarray] = {}\n",
    "    \n",
    "    params = dict(\n",
    "        df=grouped,\n",
    "        computed=computed,\n",
    "        t_min=graph.timestamps.min(),\n",
    "        t_max=graph.timestamps.max(),\n",
    "        lower_bound=lower_bound\n",
    "    )\n",
    "    \n",
    "    features_list = []\n",
    "    for first_id, second_id, *_ in tqdm(edges):\n",
    "        features_list.append(\n",
    "            _get_temporal_features_for_pair(graph, first_id, second_id, **params)\n",
    "        )\n",
    "    \n",
    "    return np.vstack(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4351569-1f41-479c-8764-40f5290cbd1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_intersection(first, second):\n",
    "    i = j = k = 0\n",
    "    buffer = np.empty(min(first.size, second.size), dtype=first.dtype)\n",
    "    while i < first.size and j < second.size:\n",
    "        if first[i] == second[j]:\n",
    "            buffer[k] = first[i]\n",
    "            k += 1\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif first[i] < second[j]:\n",
    "            i += 1\n",
    "        else: \n",
    "            j += 1\n",
    "    return buffer[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74cf05c6-bebc-433a-956a-c8c54fab02db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from queue import deque\n",
    "\n",
    "def get_connected_comps(graph: Graph) -> list[list[int]]:\n",
    "    visited = {u_id : False for u_id in graph.nodes}\n",
    "    queue = deque(graph.nodes)\n",
    "    conn_comps: list[list[int]] = []\n",
    "    \n",
    "    for root_u_id in graph.nodes.keys():\n",
    "        if visited[root_u_id]:\n",
    "            continue\n",
    "            \n",
    "        queue = deque([root_u_id])\n",
    "        conn_comps.append([])\n",
    "        \n",
    "        while queue:\n",
    "            u_id = queue.popleft()\n",
    "            conn_comps[-1].append(u_id)\n",
    "            if not visited[u_id]:\n",
    "                for neighbor_id in graph.nodes[u_id].neighbors:\n",
    "                    if not visited[neighbor_id]:\n",
    "                        queue.append(neighbor_id)\n",
    "                        visited[neighbor_id] = True\n",
    "    return conn_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d1ecac8-846e-48f8-b1e6-ce09da00173b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr \n",
    "\n",
    "def get_avg_cluster_coeff(graph: Graph) -> float:\n",
    "    return np.nanmean([graph.get_subgraph(node.neighbors).density\n",
    "                       for node in graph.nodes.values()])\n",
    "\n",
    "def get_deg_assortivity(graph: Graph) -> float:\n",
    "    degs = np.vectorize(lambda node_id: graph.nodes[node_id].deg)(graph.edges_set)\n",
    "    return pearsonr(degs[:, 0], degs[:, 1]).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4a1e6a3-b75d-45ff-801e-3b3afbb3866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "def load_graph(path, time_quantile: float = .8) -> StaticGraph:\n",
    "    network = Network(path)\n",
    "    return StaticGraph.from_time_slice(network, time_quantile)\n",
    "\n",
    "def compute_features(graph):\n",
    "    train_set = get_train_set(graph)\n",
    "    static = compute_static_features(graph, train_set)\n",
    "    temporal = compute_temporal_features(graph, train_set, .2)\n",
    "    return {\n",
    "        \"edges_labels\": train_set,\n",
    "        \"static\": static,\n",
    "        \"second_a\": temporal\n",
    "    }\n",
    "\n",
    "def save(features_dict, name):\n",
    "    folder = Path(\"./features_compiled\")\n",
    "    if not folder.exists():\n",
    "        folder.mkdir()\n",
    "        \n",
    "    with (folder / name).open(\"wb\") as f:\n",
    "        pickle.dump(features_dict, f)\n",
    "\n",
    "def load(name):\n",
    "    folder = Path(\"./features_compiled\")\n",
    "    \n",
    "    with (folder / name).open(\"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8321e762-5a53-482c-9187-0a843a3183d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def first_task(graph):\n",
    "    num_vertices = len(graph.nodes)\n",
    "    num_edges = len(graph.edges_set)\n",
    "    density = 2 * num_edges / num_vertices / (num_vertices - 1)\n",
    "\n",
    "    conn_comps = get_connected_comps(graph)\n",
    "    conn_comp = graph.get_subgraph(max(conn_comps, key=len))\n",
    "    max_conn_comp_fraction =  len(conn_comp.nodes) / num_vertices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47420c68-1314-40b6-a672-8e4a2ca8a240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph = load_graph(\"./data/radoslaw_email/out.radoslaw_email_email\")\n",
    "features = compute_features(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0dad081-7103-4f09-ba29-21a7f75d9381",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(features, \"radoslaw_email.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
